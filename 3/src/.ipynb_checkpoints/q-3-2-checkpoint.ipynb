{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score,confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"wine-quality/data.csv\")\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "# df\n",
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.iloc[:,0:12].values\n",
    "# # print(X)\n",
    "# FX = []\n",
    "# a=0\n",
    "# for i in X:\n",
    "# #     print(i)\n",
    "#     if X[a][len(i)-1]==4 or X[a][len(i)-1]==5 or X[a][len(i)-1]==6 or X[a][len(i)-1]==7 or X[a][len(i)-1]==8:\n",
    "#         FX.append(i)\n",
    "#     a=a+1\n",
    "# # FX\n",
    "# df = pd.DataFrame(FX, columns=columns)\n",
    "# # df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['quality'],axis=1)\n",
    "Y = df['quality']\n",
    "\n",
    "# print(len(df[df['quality']==9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean())/X_train.std()\n",
    "X_test = (X_test - X_test.mean())/X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5351473922902494\n",
      "0.5351473922902494\n",
      "[[  0   1   0   0   0   0   0]\n",
      " [  0   1  19  11   0   0   0]\n",
      " [  0   0 132 138   1   0   0]\n",
      " [  0   0  66 298  30   0   0]\n",
      " [  0   0   6 101  41   0   0]\n",
      " [  0   0   1  23  11   0   0]\n",
      " [  0   0   0   1   1   0   0]]\n",
      "53.51473922902494\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs',multi_class='multinomial',max_iter=iterations)\n",
    "lr.fit(X_train, Y_train) \n",
    "y_pred = lr.predict(X_test)\n",
    "score = lr.score(X_test,Y_test)\n",
    "print(score)\n",
    "print((Y_test == y_pred).mean())\n",
    "print(confusion_matrix(Y_test,y_pred))\n",
    "# print(classification_report(Y_test,y_pred))\n",
    "print(accuracy_score(Y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train,Y_train],axis=1)\n",
    "ones = np.ones([X_train.shape[0],1])\n",
    "Y_train = X_train.iloc[:,11:12].values\n",
    "X_train = X_train.iloc[:,0:11]\n",
    "X_train = np.concatenate((ones,X_train),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3526, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.zeros([11,12])\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_decent(X_train,Y_train,theta1,learning_rate,iterations):\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        h = sigmoid(np.dot(X_train,theta1.T))\n",
    "        theta1 = theta1 - (learning_rate/len(X_train)) * np.sum(X_train * (h - Y_train), axis=0)\n",
    "    \n",
    "    return theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,11):\n",
    "    theta1 = np.zeros([1,12])\n",
    "    W = np.array(Y_train)\n",
    "    for j in range(len(W)):\n",
    "        if W[j] == i:\n",
    "            W[j] = 1\n",
    "        else:\n",
    "            W[j] = 0\n",
    "    \n",
    "    theta[i]=gradient_decent(X_train,W,theta1,learning_rate,iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for index,rows in X_test.iterrows():\n",
    "\n",
    "    rows = list(rows)\n",
    "    max_h=0\n",
    "    for a in range(0,11):\n",
    "        y = 0\n",
    "        for i in range(len(rows)):\n",
    "            y = y + rows[i]*theta[a][i+1]\n",
    "        y = y + theta[a][0]\n",
    "        y = sigmoid(y)\n",
    "        if y >= max_h:\n",
    "            label = a\n",
    "            max_h = y\n",
    "    y_pred.append(label)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.6281179138322\n",
      "[[  0   0   1   0   0   0   0]\n",
      " [  0   0  20  11   0   0   0]\n",
      " [  0   0 142 129   0   0   0]\n",
      " [  0   0  66 317  11   0   0]\n",
      " [  0   0   9 125  14   0   0]\n",
      " [  0   0   1  30   4   0   0]\n",
      " [  0   0   0   1   1   0   0]]\n",
      "53.6281179138322\n"
     ]
    }
   ],
   "source": [
    "print((y_pred == Y_test).mean()*100)\n",
    "print(confusion_matrix(Y_test,y_pred))\n",
    "# print(classification_report(Y_test,y_pred))\n",
    "print(accuracy_score(Y_test, y_pred)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
