{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aacOF7cfxC65"
   },
   "source": [
    "#### Q1 - Train and validate an n-layer Neural Network on apparel dataset to predict the class label of a given apparel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvB4y9vV5UNr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "fHrbbG-X8yXU",
    "outputId": "7e502024-d430-43cf-9401-aad1f540ed77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tx8MpTp3x79q"
   },
   "source": [
    "#### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Khb_zbWw8wWP"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/apparel-trainval.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8kmay_yyHyM"
   },
   "source": [
    "#### split data into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "INODBK069TN2"
   },
   "outputs": [],
   "source": [
    "data = shuffle(data).reset_index(drop=True)\n",
    "index = int(0.8 * len(data))\n",
    "data_train = data[:index]\n",
    "data_test = data[index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3PbUT14HyZwS"
   },
   "source": [
    "#### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ify9W1sAOmiz"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(Y, unique_labels):\n",
    "    y_mat = np.zeros((Y.shape[0], len(unique_labels)))\n",
    "    for i in range(len(Y)):\n",
    "        y_mat[i][Y[i]] = 1\n",
    "    return y_mat\n",
    "\n",
    "def activation_func(function_name):\n",
    "    fun = \"\"\n",
    "    del_fun = \"\"\n",
    "    if function_name == \"relu\":\n",
    "        fun = relu\n",
    "        del_fun = delta_relu\n",
    "        \n",
    "    elif function_name == \"tanh\":\n",
    "        fun = tan_h\n",
    "        del_fun = delta_tan_h\n",
    "        \n",
    "    elif function_name == \"sigmoid\":\n",
    "        fun = sigmoid\n",
    "        del_fun = delta_sigmoid\n",
    "    return fun, del_fun\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "  \n",
    "def delta_sigmoid(x):\n",
    "    sig = sigmoid(x)\n",
    "    return sig * (1. - sig)\n",
    "  \n",
    "def softmax(x):\n",
    "    shift_x = x - np.array([np.max(x, axis=1)]).T\n",
    "    exps = np.exp(shift_x)\n",
    "    return exps / np.array([np.sum(exps, axis=1)]).T\n",
    "    \n",
    "def delta_softmax(x):\n",
    "    soft = softmax(x)\n",
    "    return soft * (1. - soft)\n",
    "\n",
    "def tan_h(x):\n",
    "    return np.tanh(x)\n",
    "  \n",
    "def delta_tan_h(x):\n",
    "    return 1.0 - np.tanh(x)**2\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0.0, x) \n",
    "  \n",
    "def delta_relu(x):\n",
    "    x[x > 0] = 1\n",
    "    x[x <= 0] = 0\n",
    "    return x\n",
    "  \n",
    "def delta_mean_square_error(y_, y):\n",
    "    return (y_ - y)\n",
    "  \n",
    "def cross_entropy(predictions, targets, epsilon = 1e-12):\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets * np.log(predictions + 1e-9))/N\n",
    "    return ce\n",
    "\n",
    "# def user_input():\n",
    "#     layers = int(input(\"Enter the number of hidden layers: \"))\n",
    "#     neurons = []\n",
    "#     for i in range(layers):\n",
    "#         print(\"Enter the number of neurons in layer \", i, \": \")\n",
    "#         temp = input()\n",
    "#         neurons.append(int(temp))\n",
    "#     batch_size = int(input(\"Enter the batch size: \"))\n",
    "#     epochs = int(input(\"Enter the number of epochs: \"))\n",
    "#     return layers, neurons, batch_size, epochs\n",
    "  \n",
    "def save_weights(best_weights):\n",
    "    np.save('/content/gdrive/My Drive/Colab Notebooks/best_weights.npy', best_weights)\n",
    "    \n",
    "def load_weights():\n",
    "    loaded_weights = np.load('/content/gdrive/My Drive/Colab Notebooks/best_weights.npy')\n",
    "    return loaded_weights\n",
    "  \n",
    "def model_acc(model):\n",
    "    test_x = data_test.iloc[:,1:]\n",
    "    test_x = StandardScaler().fit_transform(test_x)\n",
    "    \n",
    "    predicted_y = model.test(test_x)\n",
    "    predicted_y = np.argmax(predicted_y, axis=1)\n",
    "    return accuracy_score(data_test.iloc[:,0], predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3WOn_tn-izB"
   },
   "outputs": [],
   "source": [
    "X = data_train.iloc[:,1:]\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "Y = data_train.iloc[:,0]\n",
    "\n",
    "unique_labels = np.unique(Y).tolist() \n",
    "Y = one_hot_encode(Y, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZRAP2Hqi6t_"
   },
   "source": [
    "#### Neural Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnicWAq-GBNK"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,layers, neurons, output_labels, features, batch_size, epochs, function_name, load_from_file, alpha=0.00001):\n",
    "        if load_from_file == 1:\n",
    "            self.weights = load_weights()\n",
    "        else:\n",
    "            self.weights = np.empty(layers + 1, dtype = object)\n",
    "\n",
    "        for i in range(len(self.weights)):\n",
    "            if i == layers:\n",
    "                _range =  np.sqrt(1. / neurons[i - 1])\n",
    "                self.weights[i] = np.random.uniform(-_range,_range,(neurons[i - 1], len(output_labels)))\n",
    "            elif i == 0:\n",
    "                _range =  np.sqrt(1. / features)\n",
    "                self.weights[i] = np.random.uniform(-_range,_range,(features, neurons[i])) \n",
    "            else:\n",
    "                _range =  np.sqrt(1. / neurons[i - 1])\n",
    "                self.weights[i] =  np.random.uniform(-_range,_range,(neurons[i-1], neurons[i]))\n",
    "        \n",
    "        \n",
    "        self.fun, self.delta_fun = activation_func(function_name)\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.layers = layers\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.output_labels = output_labels\n",
    "\n",
    "    def back_prop(self,X, y):\n",
    "        delta_weights = np.empty(layers + 1, dtype = object)\n",
    "        for i in range(len(self.weights) - 1, -1, -1): \n",
    "          if i == self.layers:\n",
    "              delta_weights[i] = np.multiply(delta_mean_square_error(self.h_out[-1], y), delta_softmax(self.h_in[-1]))\n",
    "          else: \n",
    "              delta_weights[i] = np.multiply(np.dot(delta_weights[i+1], self.weights[i+1].T), self.delta_fun(self.h_in[i]))\n",
    "\n",
    "        for i in range(layers + 1):\n",
    "            if i == 0:\n",
    "                self.weights[i] -= self.alpha * np.dot(X.T, delta_weights[i])\n",
    "            else:\n",
    "                self.weights[i] -= self.alpha * np.dot(self.h_out[i-1].T, delta_weights[i])\n",
    "    \n",
    "    def feed_forward(self,X):\n",
    "        self.h_in = np.empty(layers + 1, dtype = object)\n",
    "        self.h_out = np.empty(layers + 1, dtype = object)\n",
    "        for i in range(len(self.weights)):\n",
    "            if i == self.layers:\n",
    "                self.h_in[i] = np.dot(self.h_out[i - 1], self.weights[i])\n",
    "                self.h_out[i] = softmax(self.h_in[i])\n",
    "            elif i == 0:\n",
    "                self.h_in[i] = np.dot(X, self.weights[i])\n",
    "                self.h_out[i] = self.fun(self.h_in[i])\n",
    "            else:\n",
    "                self.h_in[i] = np.dot(self.h_out[i - 1], self.weights[i])\n",
    "                self.h_out[i] = self.fun(self.h_in[i])                      \n",
    "                \n",
    "    def train(self,X, y):\n",
    "        all_costs = []\n",
    "        for i in range(self.epochs):\n",
    "            cost = 0\n",
    "            for j in range(0, X.shape[0], self.batch_size):\n",
    "                X_batch = X[j:j+self.batch_size]   \n",
    "                Y_batch = y[j:j+self.batch_size]\n",
    "                self.feed_forward(X_batch)\n",
    "                self.back_prop(X_batch, Y_batch)\n",
    "                cost += cross_entropy(self.h_out[-1], Y_batch)\n",
    "            if i%10 == 1:    \n",
    "                print(i,cost / self.batch_size)\n",
    "            all_costs.append(cost / self.batch_size)\n",
    "        return all_costs\n",
    "            \n",
    "    def test(self,test_x):\n",
    "        self.feed_forward(test_x)\n",
    "        y_ = self.h_out[-1]\n",
    "        return y_\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8-X9f50jBp_"
   },
   "source": [
    "#### calling neural network with all 3 activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2638
    },
    "colab_type": "code",
    "id": "sMHYBjHf8Dkk",
    "outputId": "64d4c7a4-2f1e-4471-89cd-91596d97a52f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.15332576147747315)\n",
      "(11, 0.08986631441809424)\n",
      "(21, 0.07954285641773486)\n",
      "(31, 0.07405548561501811)\n",
      "(41, 0.0702819494196591)\n",
      "(51, 0.06736964519517878)\n",
      "(61, 0.0649909750497204)\n",
      "(71, 0.0629824769146845)\n",
      "(81, 0.0612212641073412)\n",
      "(91, 0.059623698149485885)\n",
      "(101, 0.05815686184266558)\n",
      "(111, 0.056803487895675596)\n",
      "(121, 0.055559674078321734)\n",
      "(131, 0.054417181773735716)\n",
      "(141, 0.053372393241896285)\n",
      "(151, 0.052398666537587714)\n",
      "(161, 0.05147450262435329)\n",
      "(171, 0.05059997901927139)\n",
      "(181, 0.049752811975780055)\n",
      "(191, 0.048937784844069694)\n",
      "(201, 0.048154010847911904)\n",
      "(211, 0.047396870912805006)\n",
      "(221, 0.046667623545383376)\n",
      "(231, 0.04597405441127638)\n",
      "(241, 0.045315046497022615)\n",
      "(251, 0.04468488930053898)\n",
      "(261, 0.04407980995299723)\n",
      "(271, 0.04349566303741946)\n",
      "(281, 0.04292844931551797)\n",
      "(291, 0.04237448661292589)\n",
      "(301, 0.04184356263433706)\n",
      "(311, 0.04133391699965945)\n",
      "(321, 0.04084699916715526)\n",
      "(331, 0.040380228411745274)\n",
      "(341, 0.03993019345917042)\n",
      "(351, 0.03949384843947375)\n",
      "(361, 0.03906906619640456)\n",
      "(371, 0.03865454356130884)\n",
      "(381, 0.03825360617687804)\n",
      "(391, 0.037867207796100914)\n",
      "(401, 0.037494282881342364)\n",
      "(411, 0.03713529045263633)\n",
      "(421, 0.03679010411338339)\n",
      "(431, 0.036457018183797936)\n",
      "(441, 0.03613638204570435)\n",
      "(451, 0.03582780050042995)\n",
      "(461, 0.035529020416583526)\n",
      "(471, 0.03523705194178197)\n",
      "(481, 0.03495238408278867)\n",
      "(491, 0.034676986579582826)\n",
      "('For function sigmoid, acccuracy is', 0.86825, 'cost is', [0.2783719759504238, 0.15332576147747315, 0.1289390701725788, 0.11784491856459012, 0.11066790892583847, 0.10550073706435312, 0.1015336604066762, 0.09835085706542683, 0.09571701582231752, 0.09348520838036875, 0.09155758358376491, 0.08986631441809424, 0.08836316753601713, 0.08701326929882998, 0.08579075568154738, 0.0846758333865109, 0.08365290153412713, 0.08270930062793722, 0.08183457773602006, 0.08102000872533234, 0.0802582144922677, 0.07954285641773486, 0.07886843274287911, 0.07823016049176883, 0.07762393005438405, 0.07704635279345935, 0.0764947313224869, 0.07596678459704445, 0.07546050277209641, 0.07497414101667098, 0.07450621568191311, 0.07405548561501811, 0.07362088470912835, 0.07320143157609424, 0.07279616895535922, 0.0724041497836007, 0.07202444811468586, 0.07165617578747778, 0.07129850054272681, 0.07095066529654145, 0.07061200496731992, 0.0702819494196591, 0.06996000449821443, 0.06964573146643234, 0.06933874368892715, 0.06903870345771378, 0.06874531266589372, 0.06845830691613856, 0.0681774502100932, 0.06790252604214839, 0.06763332688320285, 0.06736964519517878, 0.06711126822328621, 0.06685797700877076, 0.06660954787964815, 0.06636575640866431, 0.0661263874564216, 0.06589125310770981, 0.06566021456145091, 0.06543319146225259, 0.0652101343516106, 0.0649909750497204, 0.06477559699636393, 0.06456383906248464, 0.06435552660861528, 0.06415050073140699, 0.06394862724154501, 0.06374978959272995, 0.06355387569547485, 0.06336076863080253, 0.06317034495655324, 0.0629824769146845, 0.06279703507327898, 0.06261389391993033, 0.06243294682373392, 0.06225411073596096, 0.06207731101438014, 0.06190250545522391, 0.061729613356035246, 0.06155850217364017, 0.06138907423130695, 0.0612212641073412, 0.06105502062788427, 0.06089029959742953, 0.06072706225587272, 0.060565275669210245, 0.060404912168564126, 0.06024594725226162, 0.06008835886470711, 0.05993212925296993, 0.05977724584844719, 0.059623698149485885, 0.05947147183511257, 0.059320544080135436, 0.05917088356830235, 0.059022456116856664, 0.05887523389017728, 0.05872920309200534, 0.05858436312437266, 0.05844071303116399, 0.058298231004800444, 0.05815686184266558, 0.05801652696229059, 0.057877177841451834, 0.05773887973740621, 0.05760169761409453, 0.057465655175193135, 0.05733077373647453, 0.057197083320889915, 0.057064621533283365, 0.05693346506297876, 0.056803487895675596, 0.05667458531435495, 0.05654673864104474, 0.056419927930198364, 0.0562941303059737, 0.0561693249111971, 0.0560454962932225, 0.05592263602201754, 0.055800734130929265, 0.055679752020165174, 0.055559674078321734, 0.05544057922405708, 0.055322545610500984, 0.0552056106693019, 0.05508977525928703, 0.05497500952679822, 0.054861252823870436, 0.054748489702468234, 0.054636945994395565, 0.05452657900217697, 0.054417181773735716, 0.05430873699417963, 0.05420124101794221, 0.05409467719705683, 0.05398901856598138, 0.05388423495073444, 0.05378029739806991, 0.05367717730572765, 0.05357484396809792, 0.053473263238383445, 0.053372393241896285, 0.053272175448394195, 0.05317261492083136, 0.05307380382119798, 0.052975669146394164, 0.052878112584026644, 0.05278108893404421, 0.0526846982496242, 0.05258889645022281, 0.05249357043735894, 0.052398666537587714, 0.05230416396455722, 0.052210058268610283, 0.05211635725821903, 0.05202307908880944, 0.05193025444908952, 0.05183793129656098, 0.051746167860202016, 0.05165500830042741, 0.05156446145010408, 0.05147450262435329, 0.0513850906537499, 0.05129618209872932, 0.05120773660682344, 0.05111971867899423, 0.05103211626748968, 0.05094496530107663, 0.050858236019805936, 0.05077184756251431, 0.05068577002684434, 0.05059997901927139, 0.05051442083938727, 0.05042899274454586, 0.0503435874560297, 0.050258230542536024, 0.050173075887364776, 0.05008823990118843, 0.05000378028643578, 0.04991972255955398, 0.04983606943933408, 0.049752811975780055, 0.04966993505057797, 0.049587419935759096, 0.049505245008673954, 0.049423385423486905, 0.04934182062905253, 0.0492605409679686, 0.04917953142432808, 0.04909875296978988, 0.049018139750431275, 0.048937784844069694, 0.04885816611403886, 0.04877894638153178, 0.04869993919618426, 0.048621164364927326, 0.048542640464754094, 0.04846437872507335, 0.04838638579335581, 0.04830866469055516, 0.04823121227678317, 0.048154010847911904, 0.048077016931256183, 0.048000180502276564, 0.04792353068229972, 0.04784720095238593, 0.04777128132132475, 0.04769575441961089, 0.047620575884219626, 0.04754571525065573, 0.04747115269243068, 0.047396870912805006, 0.047322850898246255, 0.04724907407106197, 0.047175530747376994, 0.04710222353424859, 0.047029142660339925, 0.04695624631054959, 0.04688352425007012, 0.04681109362518095, 0.046739120256310177, 0.046667623545383376, 0.04659652218523186, 0.04652577177975196, 0.046455392977357485, 0.046385428016141324, 0.04631589377748825, 0.04624677706507865, 0.046178053841064104, 0.04610970232237144, 0.04604170632223582, 0.04597405441127638, 0.04590673830884244, 0.04583975150851927, 0.045773087976145536, 0.04570674061095058, 0.04564070127870081, 0.04557496530061587, 0.04550953325536042, 0.045444405214908036, 0.04537957796206235, 0.045315046497022615, 0.04525080542779299, 0.04518684946726982, 0.045123173524222716, 0.04505977268642527, 0.04499664219411135, 0.044933777424503586, 0.04487117389159498, 0.04480882727895107, 0.044746733559539204, 0.04468488930053898, 0.04462329221700765, 0.04456194169334806, 0.044500838353939094, 0.04443998214936011, 0.04437937052656553, 0.04431899865303028, 0.04425886104760275, 0.04419895282354304, 0.044139270093529186, 0.04407980995299723, 0.044020570307276505, 0.043961549416167006, 0.04390274471166851, 0.043844150262646264, 0.04378574922022273, 0.043727498920115675, 0.04366935487377698, 0.043611318788152324, 0.043553415012518394, 0.04349566303741946, 0.043438077073806335, 0.04338066995550365, 0.043323453240845654, 0.043266435094133256, 0.04320961889582786, 0.04315300359118505, 0.043096585122397855, 0.04304035783011182, 0.0429843151252039, 0.04292844931551797, 0.04287275067678022, 0.04281720554004974, 0.042761792160852526, 0.042706470600724245, 0.04265115765990709, 0.04259568592192985, 0.042539902067773916, 0.042484202304964566, 0.04242910884024298, 0.04237448661292589, 0.04232022188535462, 0.04226627903934996, 0.04221262897843192, 0.042159243843416024, 0.04210610096219413, 0.04205318334184382, 0.04200047846853099, 0.041947977201894554, 0.041895673175867246, 0.04184356263433706, 0.04179164454534183, 0.041739920791632114, 0.04168839616772119, 0.04163707790594118, 0.04158597461326808, 0.04153509481739575, 0.041484445590599675, 0.04143403170238862, 0.041383855450845365, 0.04133391699965945, 0.04128421492469816, 0.04123474674231714, 0.04118550931814743, 0.04113649914536729, 0.041087712519276995, 0.041039145640878114, 0.040990794676822324, 0.040942655796789046, 0.04089472520393794, 0.04084699916715526, 0.0407994740533315, 0.04075214634722979, 0.040705012644530296, 0.04065806961542434, 0.04061131395339155, 0.040564742331431175, 0.04051835138082922, 0.04047213769408285, 0.04042609784434663, 0.040380228411745274, 0.040334526009214125, 0.04028898730363439, 0.04024360903027177, 0.040198387999788254, 0.04015332109785152, 0.04010840527803319, 0.040063637549488496, 0.04001901496184247, 0.03997453459062358, 0.03993019345917042, 0.039885988575962955, 0.03984191725194831, 0.03979797666758281, 0.03975416409290378, 0.03971047693864376, 0.03966691281392499, 0.03962346958244988, 0.03958014540645789, 0.03953693876581643, 0.03949384843947375, 0.039450873439479936, 0.03940801289493175, 0.03936526589424044, 0.03932263130683844, 0.03928010761624809, 0.03923769280237323, 0.03919538431133894, 0.03915317914732203, 0.039111074111886954, 0.03906906619640456, 0.03902715309330847, 0.03898533373271876, 0.03894360869883116, 0.0389019803866361, 0.03886045285696843, 0.03881903149189741, 0.038777722630155484, 0.038736533300989244, 0.03869547102738272, 0.03865454356130884, 0.03861375842567106, 0.03857312225974374, 0.038532640120266255, 0.03849231497823046, 0.038452147604481686, 0.03841213687806758, 0.03837228038400214, 0.038332575090539944, 0.03829301792779721, 0.03825360617687804, 0.038214337660735904, 0.03817521077604046, 0.03813622442071113, 0.0380973778674955, 0.0380586706216196, 0.03802010228682144, 0.03798167245184808, 0.037943380599416106, 0.03790522603133308, 0.037867207796100914, 0.0378293245979113, 0.037791574657888176, 0.037753955491880396, 0.03771646358096592, 0.03767909403016481, 0.03764184095958187, 0.03760470224482344, 0.03756769946639944, 0.0375308969030486, 0.037494282881342364, 0.03745776838587955, 0.03742135980726921, 0.03738507757249977, 0.037348938125663575, 0.037312951042915855, 0.03727711897091704, 0.03724144041129947, 0.037205912037738216, 0.037170529987592876, 0.03713529045263633, 0.03710018990291088, 0.03706522514525717, 0.037030393316718944, 0.036995691855416644, 0.03696111846242399, 0.036926671055217394, 0.03689234771079851, 0.03685814660427464, 0.036824065967208656, 0.03679010411338339, 0.036756259585115594, 0.03672253134095717, 0.03668891933857378, 0.03665542441113778, 0.036622048228502936, 0.03658879292567434, 0.03655566066924188, 0.03652265331592487, 0.036489772221340526, 0.036457018183797936, 0.03642439147894549, 0.03639189194109976, 0.03635951905986873, 0.036327272075750275, 0.03629515007005105, 0.0362631520507399, 0.036231277036909044, 0.03619952414134209, 0.036167892644501924, 0.03613638204570435, 0.03610499207093763, 0.036073722615425734, 0.03604257360646605, 0.03601154478993677, 0.03598063546882378, 0.03594984424514945, 0.03591916882677265, 0.035888605951590456, 0.03585815145767179, 0.03582780050042995, 0.03579754789527476, 0.03576738853780477, 0.03573731780433923, 0.035707331781044155, 0.03567742719861333, 0.0356476011150912, 0.03561785056487361, 0.03558817239569187, 0.035558563364282626, 0.035529020416583526, 0.03549954102488715, 0.035470123466724894, 0.0354407669653439, 0.03541147165571984, 0.035382238393404625, 0.03535306847652465, 0.03532396338090166, 0.035294924595793614, 0.03526595359793086, 0.03523705194178197, 0.0352082214037097, 0.03517946410949056, 0.035150782592400516, 0.03512217975790202, 0.03509365875837755, 0.03506522280207343, 0.035036874934359204, 0.035008617836283805, 0.03498045368222768, 0.03495238408278867, 0.034924410114320625, 0.034896532412561576, 0.034868751294667315, 0.034841066875294674, 0.034813479153941174, 0.03478598806493625, 0.034758593492402824, 0.03473129525799167, 0.03470409308992555, 0.034676986579582826, 0.03464997512800514, 0.03462305788007857, 0.034596233638637286, 0.03456950074334575, 0.03454285688756607, 0.03451629882560013, 0.03448982188244999, 0.03446341909601908])\n",
      "(1, 0.37287855981957496)\n",
      "(11, 0.1968585778491192)\n",
      "(21, 0.15841678746174984)\n",
      "(31, 0.14008115032279125)\n",
      "(41, 0.12930474907485115)\n",
      "(51, 0.12197424007035992)\n",
      "(61, 0.11651361799022573)\n",
      "(71, 0.11224394865862942)\n",
      "(81, 0.10879777809831015)\n",
      "(91, 0.1059434947515538)\n",
      "(101, 0.10352591203255342)\n",
      "(111, 0.10143895705487557)\n",
      "(121, 0.0996091182103665)\n",
      "(131, 0.09798449385616478)\n",
      "(141, 0.09652756022945402)\n",
      "(151, 0.09521044782191763)\n",
      "(161, 0.09401186835280952)\n",
      "(171, 0.09291511271520304)\n",
      "(181, 0.09190673002531997)\n",
      "(191, 0.09097563567180364)\n",
      "(201, 0.09011250201421654)\n",
      "(211, 0.08930934905820989)\n",
      "(221, 0.0885592777785915)\n",
      "(231, 0.08785629656409387)\n",
      "(241, 0.08719519944159354)\n",
      "(251, 0.08657146862438649)\n",
      "(261, 0.08598118833194672)\n",
      "(271, 0.0854209662409659)\n",
      "(281, 0.08488786260767453)\n",
      "(291, 0.08437932723929191)\n",
      "(301, 0.08389314364348797)\n",
      "(311, 0.08342737952770671)\n",
      "(321, 0.08298034352689937)\n",
      "(331, 0.08255054848050827)\n",
      "(341, 0.08213668099538123)\n",
      "(351, 0.08173757615040877)\n",
      "(361, 0.08135219601536063)\n",
      "(371, 0.08097961113358894)\n",
      "(381, 0.0806189846372766)\n",
      "(391, 0.08026955887346737)\n",
      "(401, 0.07993064437166497)\n",
      "(411, 0.07960161086842897)\n",
      "(421, 0.07928188004438592)\n",
      "(431, 0.07897091964700836)\n",
      "(441, 0.07866823873827267)\n",
      "(451, 0.07837338388236634)\n",
      "(461, 0.0780859361454234)\n",
      "(471, 0.07780550879085636)\n",
      "(481, 0.07753174549343576)\n",
      "(491, 0.07726431875159295)\n",
      "('For function tanh, acccuracy is', 0.8599166666666667, 'cost is', [0.42187438190499627, 0.37287855981957496, 0.33321264104857834, 0.30291412236369225, 0.2793708044392926, 0.2603686163618309, 0.24467162753173147, 0.23158004659491876, 0.22061916602649126, 0.2113993137325719, 0.20357667759772874, 0.1968585778491192, 0.19101050440495607, 0.18585232811677208, 0.18124828356027187, 0.17709637185420454, 0.17331959016540266, 0.16985931802523685, 0.16667047682735323, 0.16371799068296536, 0.16097417418623228, 0.15841678746174984, 0.15602758559205424, 0.15379124516919385, 0.15169458342277636, 0.14972600408009165, 0.14787511570877754, 0.14613247712837113, 0.1444894326222783, 0.14293800759216374, 0.1414708426343251, 0.14008115032279125, 0.13876268402312622, 0.13750971187015837, 0.1363169918150527, 0.13517974560786272, 0.13409363092101367, 0.1330547116796245, 0.13205942715587218, 0.13110456059964792, 0.13018720820001914, 0.12930474907485115, 0.12845481682917034, 0.1276352730503296, 0.12684418294787447, 0.1260797932129847, 0.1253405120714657, 0.1246248914342162, 0.1239316110053903, 0.12325946418536789, 0.12260734559757926, 0.12197424007035992, 0.12135921291354793, 0.12076140134164587, 0.12018000690908427, 0.11961428883714662, 0.11906355812562597, 0.1185271723548394, 0.11800453109499949, 0.11749507185006941, 0.11699826647214859, 0.11651361799022573, 0.11604065780392711, 0.11557894319878781, 0.11512805514472312, 0.1146875963438672, 0.114257189497893, 0.11383647576839227, 0.11342511340695886, 0.11302277653433111, 0.1126291540503498, 0.11224394865862942, 0.11186687599173273, 0.11149766382433729, 0.1111360513633779, 0.11078178860549805, 0.1104346357533301, 0.11009436268319062, 0.10976074845771935, 0.10943358087783181, 0.10911265606909706, 0.10879777809831015, 0.10848875861660758, 0.10818541652598584, 0.1078875776665219, 0.10759507452198967, 0.10730774594189786, 0.10702543687826661, 0.1067479981357105, 0.10647528613360745, 0.10620716267931561, 0.1059434947515538, 0.10568415429318873, 0.10542901801278348, 0.10517796719434913, 0.10493088751481812, 0.10468766886881965, 0.10444820520038857, 0.10421239434127955, 0.10398013785559684, 0.10375134089047232, 0.10352591203255342, 0.10330376317007653, 0.10308480936032063, 0.10286896870224646, 0.10265616221413736, 0.10244631371606856, 0.10223934971703508, 0.10203519930657955, 0.1018337940507619, 0.1016350678923204, 0.10143895705487557, 0.10124539995103504, 0.10105433709425486, 0.1008657110143235, 0.10067946617633144, 0.10049554890299481, 0.10031390730020581, 0.1001344911856826, 0.0999572520205974, 0.09978214284406359, 0.0996091182103665, 0.09943813412882561, 0.09926914800618, 0.09910211859139424, 0.09893700592278187, 0.09877377127735154, 0.09861237712228253, 0.09845278706844078, 0.09829496582585001, 0.09813887916103563, 0.09798449385616478, 0.09783177766990593, 0.09768069929993727, 0.09753122834703486, 0.09738333528067551, 0.09723699140608931, 0.09709216883270444, 0.09694884044392299, 0.09680697986817409, 0.09666656145119017, 0.09652756022945402, 0.09638995190476808, 0.09625371281989736, 0.09611881993523982, 0.09598525080648018, 0.09585298356318367, 0.09572199688828885, 0.09559226999845898, 0.09546378262525387, 0.09533651499708502, 0.09521044782191763, 0.09508556227068655, 0.09496183996139085, 0.09483926294383768, 0.09471781368500277, 0.0945974750549801, 0.09447823031349148, 0.0943600630969309, 0.09424295740591661, 0.09412689759332897, 0.09401186835280952, 0.09389785470770143, 0.09378484200040928, 0.09367281588216099, 0.09356176230315295, 0.09345166750306196, 0.09334251800190813, 0.09323430059125455, 0.09312700232572985, 0.09302061051486066, 0.09291511271520304, 0.09281049672276058, 0.09270675056567976, 0.09260386249721277, 0.0925018209889382, 0.09240061472423182, 0.09230023259197873, 0.09220066368051968, 0.0921018972718243, 0.09200392283588434, 0.09190673002531997, 0.09181030867019362, 0.09171464877302453, 0.09161974050399838, 0.09152557419636619, 0.0914321403420272, 0.09133942958729004, 0.09124743272880625, 0.09115614070967229, 0.09106554461569318, 0.09097563567180364, 0.09088640523864133, 0.09079784480926677, 0.09070994600602501, 0.0906227005775444, 0.0905361003958662, 0.09045013745370163, 0.09036480386180908, 0.09028009184648912, 0.09019599374718935, 0.09011250201421654, 0.09002960920654954, 0.08994730798974813, 0.08986559113395426, 0.08978445151197871, 0.08970388209747014, 0.08962387596316101, 0.08954442627918607, 0.0894655263114691, 0.0893871694201731, 0.08930934905820989, 0.08923205876980578, 0.08915529218911827, 0.08907904303890125, 0.0890033051292136, 0.08892807235617001, 0.08885333870072817, 0.08877909822751198, 0.08870534508366565, 0.08863207349773765, 0.0885592777785915, 0.08848695231434052, 0.08841509157130505, 0.08834369009299087, 0.08827274249908518, 0.08820224348447012, 0.08813218781825206, 0.08806257034280451, 0.0879933859728245, 0.08792462969440096, 0.08785629656409387, 0.08778838170802385, 0.08772088032097096, 0.08765378766548367, 0.08758709907099399, 0.08752080993294326, 0.08745491571191347, 0.0873894119327672, 0.08732429418379432, 0.08725955811586548, 0.08719519944159354, 0.08713121393450039, 0.08706759742819191, 0.08700434581553909, 0.08694145504786631, 0.08687892113414655, 0.08681674014020364, 0.08675490818792167, 0.08669342145446157, 0.08663227617148513, 0.08657146862438649, 0.08651099515153121, 0.08645085214350283, 0.08639103604235752, 0.08633154334088643, 0.08627237058188608, 0.08621351435743643, 0.08615497130818782, 0.08609673812265524, 0.08603881153652121, 0.08598118833194672, 0.08592386533689063, 0.08586683942443653, 0.08581010751212882, 0.08575366656131607, 0.08569751357650252, 0.0856416456047081, 0.0855860597348358, 0.08553075309704715, 0.08547572286214537, 0.0854209662409659, 0.0853664804837747, 0.08531226287967401, 0.08525831075601488, 0.08520462147781703, 0.08515119244719592, 0.08509802110279611, 0.08504510491923202, 0.08499244140653475, 0.08494002810960524, 0.08488786260767453, 0.08483594251376946, 0.08478426547418509, 0.08473282916796283, 0.08468163130637493, 0.08463066963241477, 0.08457994192029282, 0.0845294459749393, 0.08447917963151161, 0.08442914075490902, 0.08437932723929191, 0.0843297370076078, 0.0842803680111236, 0.084231218228963, 0.08418228566765074, 0.08413356836066288, 0.08408506436798308, 0.08403677177566565, 0.08398868869540467, 0.08394081326410965, 0.08389314364348797, 0.08384567801963375, 0.08379841460262351, 0.08375135162611856, 0.0837044873469743, 0.08365782004485603, 0.08361134802186211, 0.08356506960215354, 0.08351898313159056, 0.08347308697737635, 0.08342737952770671, 0.0833818591914275, 0.08333652439769804, 0.08329137359566136, 0.08324640525412068, 0.08320161786122274, 0.08315700992414672, 0.0831125799688001, 0.08306832653951954, 0.0830242481987784, 0.08298034352689937, 0.08293661112177311, 0.08289304959858172, 0.08284965758952754, 0.08280643374356733, 0.08276337672615072, 0.0827204852189638, 0.08267775791967678, 0.0826351935416964, 0.08259279081392247, 0.08255054848050827, 0.0825084653006247, 0.0824665400482291, 0.08242477151183653, 0.08238315849429537, 0.08234169981256621, 0.0823003942975039, 0.08225924079364262, 0.08221823815898471, 0.08217738526479226, 0.08213668099538123, 0.0820961242479192, 0.0820557139322257, 0.08201544897057521, 0.08197532829750301, 0.08193535085961405, 0.08189551561539403, 0.08185582153502366, 0.08181626760019509, 0.0817768528039315, 0.08173757615040877, 0.08169843665478013, 0.08165943334300328, 0.08162056525167002, 0.08158183142783872, 0.08154323092886909, 0.0815047628222595, 0.08146642618548726, 0.08142822010585093, 0.08139014368031562, 0.08135219601536063, 0.0813143762268297, 0.08127668343978364, 0.08123911678835599, 0.08120167541561046, 0.08116435847340145, 0.08112716512223692, 0.08109009453114405, 0.08105314587753636, 0.08101631834708445, 0.08097961113358894, 0.08094302343885512, 0.08090655447257077, 0.0808702034521861, 0.08083396960279597, 0.08079785215702438, 0.08076185035491174, 0.08072596344380352, 0.0806901906782421, 0.08065453131986015, 0.0806189846372766, 0.08058354990599433, 0.08054822640830044, 0.08051301343316823, 0.08047791027616133, 0.08044291623934008, 0.08040803063116934, 0.0803732527664287, 0.08033858196612438, 0.08030401755740306, 0.08026955887346737, 0.08023520525349342, 0.08020095604254972, 0.08016681059151828, 0.08013276825701682, 0.08009882840132308, 0.08006499039230074, 0.08003125360332616, 0.07999761741321773, 0.07996408120616579, 0.07993064437166497, 0.0798973063044467, 0.07986406640441426, 0.07983092407657884, 0.07979787873099642, 0.07976492978270679, 0.07973207665167316, 0.07969931876272361, 0.07966665554549335, 0.07963408643436808, 0.07960161086842897, 0.07956922829139873, 0.07953693815158815, 0.07950473990184466, 0.07947263299950139, 0.07944061690632734, 0.07940869108847902, 0.07937685501645242, 0.07934510816503669, 0.07931345001326819, 0.07928188004438592, 0.07925039774578796, 0.07921900260898833, 0.07918769412957538, 0.0791564718071707, 0.07912533514538915, 0.07909428365179959, 0.07906331683788662, 0.07903243421901306, 0.07900163531438348, 0.07897091964700836, 0.0789402867436691, 0.07890973613488407, 0.07887926735487519, 0.07884887994153535, 0.07881857343639684, 0.07878834738460032, 0.0787582013348647, 0.0787281348394577, 0.07869814745416699, 0.07866823873827267, 0.07863840825451997, 0.07860865556909237, 0.07857898025158633, 0.07854938187498599, 0.07851986001563883, 0.07849041425323199, 0.07846104417076934, 0.0784317493545487, 0.0784025293941405, 0.07837338388236634, 0.07834431241527867, 0.07831531459214057, 0.07828639001540645, 0.07825753829070309, 0.07822875902681145, 0.07820005183564853, 0.07817141633224992, 0.07814285213475307, 0.07811435886438048, 0.0780859361454234, 0.07805758360522606, 0.07802930087416991, 0.07800108758565831, 0.07797294337610143, 0.07794486788490099, 0.0779168607544356, 0.07788892163004602, 0.07786105016001989, 0.07783324599557749, 0.07780550879085636, 0.07777783820289623, 0.07775023389162393, 0.07772269551983782, 0.07769522275319153, 0.07766781526017799, 0.07764047271211241, 0.0776131947831154, 0.07758598115009441, 0.07755883149272598, 0.07753174549343576, 0.07750472283737905, 0.07747776321241955, 0.07745086630910793, 0.07742403182065882, 0.07739725944292743, 0.07737054887438466, 0.07734389981609133, 0.07731731197167131, 0.07729078504728361, 0.07726431875159295, 0.07723791279573955, 0.07721156689330767, 0.07718528076029281, 0.07715905411506783, 0.07713288667834804, 0.07710677817315491, 0.07708072832477923, 0.07705473686074255])\n",
      "(1, 0.44355939379205567)\n",
      "(11, 0.4173453548568419)\n",
      "(21, 0.39060848980592966)\n",
      "(31, 0.36369612888527225)\n",
      "(41, 0.33795792531158336)\n",
      "(51, 0.31501664990118866)\n",
      "(61, 0.29557837294036604)\n",
      "(71, 0.27911723580674874)\n",
      "(81, 0.2648069086304317)\n",
      "(91, 0.2521306581549049)\n",
      "(101, 0.24085103704442837)\n",
      "(111, 0.2308649736652586)\n",
      "(121, 0.22207463620944656)\n",
      "(131, 0.21435861529387912)\n",
      "(141, 0.20758348641987334)\n",
      "(151, 0.20162943161190464)\n",
      "(161, 0.19638098408902166)\n",
      "(171, 0.19172239364578933)\n",
      "(181, 0.18754992586014857)\n",
      "(191, 0.18377669070695624)\n",
      "(201, 0.1803305285689503)\n",
      "(211, 0.17715789505866197)\n",
      "(221, 0.174218187081751)\n",
      "(231, 0.17148177024851885)\n",
      "(241, 0.1689245672269614)\n",
      "(251, 0.16652627224711464)\n",
      "(261, 0.16426991505278446)\n",
      "(271, 0.16214216776996587)\n",
      "(281, 0.16012963864205143)\n",
      "(291, 0.1582199529795143)\n",
      "(301, 0.15640473165284927)\n",
      "(311, 0.15467527762978986)\n",
      "(321, 0.1530248689444525)\n",
      "(331, 0.15144841831561442)\n",
      "(341, 0.14993991136891194)\n",
      "(351, 0.1484969047444447)\n",
      "(361, 0.14711592277270957)\n",
      "(371, 0.14579355967079405)\n",
      "(381, 0.14452795177842478)\n",
      "(391, 0.14331639521699985)\n",
      "(401, 0.14215583972882573)\n",
      "(411, 0.1410445891990973)\n",
      "(421, 0.1399814035130792)\n",
      "(431, 0.13896301607364714)\n",
      "(441, 0.1379861933392786)\n",
      "(451, 0.13704957351979735)\n",
      "(461, 0.13615077323742314)\n",
      "(471, 0.13528721270096555)\n",
      "(481, 0.13445641157925625)\n",
      "(491, 0.13365572997555072)\n",
      "('For function relu, acccuracy is', 0.7744166666666666, 'cost is', [0.44616441458312256, 0.44355939379205567, 0.44095294551802805, 0.43834479116936836, 0.4357347938336982, 0.43312142631778766, 0.43050387360121173, 0.4278820105743938, 0.42525619121857416, 0.42262473353697044, 0.4199878532873287, 0.4173453548568419, 0.4146972496709606, 0.41204259785249464, 0.40938203514252924, 0.40671564371331625, 0.4040436160083524, 0.4013661175233088, 0.3986837575209356, 0.39599641663983526, 0.3933041795501723, 0.39060848980592966, 0.38790946268245063, 0.3852085664559228, 0.3825067733335946, 0.37980561702843146, 0.37710720383457985, 0.3744126073147707, 0.37172300860140034, 0.3690393413871171, 0.36636305435538896, 0.36369612888527225, 0.36104075887721077, 0.35839861654941785, 0.35577190064906117, 0.3531624738646662, 0.35057155868107714, 0.3480009198005716, 0.34545252917064717, 0.3429281124241899, 0.34042938971687037, 0.33795792531158336, 0.3355151358656638, 0.33310252812562335, 0.330721724785803, 0.3283738915445281, 0.3260593202792331, 0.3237792350517068, 0.3215346662243278, 0.3193257482931956, 0.31715311134398794, 0.31501664990118866, 0.3129162893513304, 0.3108520442530175, 0.30882379465949533, 0.30683083520594107, 0.3048729839294484, 0.3029489935947477, 0.30105836480720055, 0.2992003560489059, 0.29737388442727264, 0.29557837294036604, 0.293812679338801, 0.29207599605982126, 0.29036738970015824, 0.2886858180038877, 0.28703038901931965, 0.28540037430380716, 0.2837949794209383, 0.2822131713058262, 0.28065429754468485, 0.27911723580674874, 0.2776010868099254, 0.276105258728038, 0.27462918524942076, 0.27317219491173284, 0.27173395089145463, 0.27031385058629387, 0.2689113891583165, 0.26752643800445425, 0.2661583930246055, 0.2648069086304317, 0.26347162608889224, 0.26215206374880556, 0.2608480619229883, 0.25955928791539484, 0.2582852536297266, 0.2570258493087862, 0.25578082862729307, 0.25455000544695927, 0.2533333341086859, 0.2521306581549049, 0.2509416150698578, 0.24976630612537312, 0.24860477841564724, 0.24745705492391754, 0.24632281040516416, 0.24520203563319748, 0.24409466421288467, 0.2430004028767881, 0.24191918891689307, 0.24085103704442837, 0.2397957743354871, 0.23875335138120093, 0.23772375108688074, 0.2367067377973577, 0.23570213670320495, 0.23471005264516864, 0.23373046490039517, 0.23276316374746273, 0.23180802481864288, 0.2308649736652586, 0.22993384478400394, 0.22901461397960782, 0.2281071417604489, 0.22721136152478374, 0.2263272551014799, 0.2254545387712226, 0.22459299319156906, 0.2237425833068464, 0.2229031181262816, 0.22207463620944656, 0.2212569700757576, 0.22044988566882087, 0.21965323607090653, 0.21886688446754574, 0.21809068979885024, 0.217324598577503, 0.21656856871887323, 0.2158223639358153, 0.2150857691729274, 0.21435861529387912, 0.2136407931853897, 0.21293230725710338, 0.2122329360397425, 0.21154262907167065, 0.21086117721754985, 0.2101884820369466, 0.2095244527798997, 0.20886903393077014, 0.20822206685682096, 0.20758348641987334, 0.20695308313776714, 0.2063307264077014, 0.20571632335403742, 0.2051096915927848, 0.2045107894068461, 0.20391967535618807, 0.2033361635670945, 0.20276002761669076, 0.20219116528021921, 0.20162943161190464, 0.2010746977867196, 0.20052692256839097, 0.1999860004311689, 0.19945180411848215, 0.198924274290934, 0.1984031879066501, 0.19788847042772767, 0.1973799350128314, 0.19687746869767153, 0.19638098408902166, 0.1958904117811957, 0.19540561619878735, 0.19492647631008728, 0.1944528782356672, 0.1939847410506096, 0.19352199449015303, 0.19306448673807708, 0.19261208986809605, 0.19216478046447785, 0.19172239364578933, 0.191284836212263, 0.19085202262700526, 0.19042385481221422, 0.19000027770609945, 0.18958120018950758, 0.18916645891646658, 0.18875603471788888, 0.18834987827639765, 0.18794788386705677, 0.18754992586014857, 0.18715593241020215, 0.18676581784437957, 0.18637951553116933, 0.18599700154427418, 0.18561817632458094, 0.18524293838926925, 0.1848712246711032, 0.18450300196608355, 0.1841381914797568, 0.18377669070695624, 0.18341843453515552, 0.18306334820872658, 0.18271135824163381, 0.18236244298716872, 0.18201657051127837, 0.18167364050413143, 0.18133361765122047, 0.18099644836209872, 0.1806621093063893, 0.1803305285689503, 0.18000165825325434, 0.17967550601276044, 0.17935204035690205, 0.17903119324689992, 0.17871288160780543, 0.17839702108690458, 0.17808358787935172, 0.17777262218259401, 0.1774640839450329, 0.17715789505866197, 0.17685402348691331, 0.17655244373690498, 0.17625309701277805, 0.17595598765877665, 0.17566105864996684, 0.17536829363258216, 0.17507763262770204, 0.1747890799943386, 0.17450259402043877, 0.174218187081751, 0.1739358128409571, 0.17365545787026265, 0.17337709616062427, 0.1731006952311299, 0.1728261887296853, 0.17255359266083897, 0.17228287686164695, 0.1720140176704099, 0.1717469812876886, 0.17148177024851885, 0.17121837901260525, 0.17095675283874065, 0.1706968255239591, 0.17043860800932192, 0.17018207696700124, 0.16992726165960445, 0.1696741269897423, 0.1694226491392578, 0.16917281384467306, 0.1689245672269614, 0.16867789217524826, 0.16843277491619044, 0.16818919403216812, 0.16794715826770307, 0.1677066592192188, 0.16746766393974133, 0.1672301482033225, 0.16699408845914493, 0.1667594722626462, 0.16652627224711464, 0.1662944957739711, 0.16606411722180356, 0.1658351154275236, 0.1656074949999373, 0.16538121406825448, 0.16515630214278657, 0.1649327470317228, 0.1647104999012276, 0.16448956089524128, 0.16426991505278446, 0.1640515675778805, 0.16383450849883757, 0.1636187107891549, 0.16340415704938813, 0.16319084239359585, 0.16297873106843952, 0.1627678115063587, 0.16255807922335624, 0.16234954277979, 0.16214216776996587, 0.16193595294823146, 0.16173085915496588, 0.16152687384064893, 0.16132398715910226, 0.16112221514501704, 0.16092154416339527, 0.1607219916726405, 0.16052350568908075, 0.16032605670879704, 0.16012963864205143, 0.15993422255791248, 0.15973982626892985, 0.1595464351187587, 0.15935404932285016, 0.1591626435840755, 0.15897218717806286, 0.1587826694629519, 0.15859412461726557, 0.15840656685697252, 0.1582199529795143, 0.1580343200067479, 0.15784964652092276, 0.15766589209625329, 0.15748304737162364, 0.15730111662529442, 0.15712008588515633, 0.15693992896714504, 0.1567606489273974, 0.15658225502061654, 0.15640473165284927, 0.15622807822916232, 0.15605226521664012, 0.15587729318817317, 0.15570315996084827, 0.15552987102201174, 0.1553573865109821, 0.15518567177240838, 0.15501476625649632, 0.15484462866823737, 0.15467527762978986, 0.15450674195093408, 0.1543390180371756, 0.1541720774059455, 0.15400589569448572, 0.1538404780505466, 0.15367581492991608, 0.15351193156490095, 0.15334882651171877, 0.15318647328675747, 0.1530248689444525, 0.15286397539508417, 0.15270380936375275, 0.15254438440210974, 0.1523856959393664, 0.15222771308541833, 0.15207044206189216, 0.15191388253997581, 0.1517580271682524, 0.15160287173477796, 0.15144841831561442, 0.1512946375906698, 0.1511415162864419, 0.15098903393253066, 0.1508372067337252, 0.1506860501697689, 0.1505355217734442, 0.15038563860779564, 0.1502363916573334, 0.150087812827629, 0.14993991136891194, 0.14979271577828232, 0.14964620001352147, 0.14950031107306982, 0.14935507617402222, 0.14921048299455317, 0.14906651323640188, 0.1489231505290285, 0.14878043449495493, 0.14863835594732605, 0.1484969047444447, 0.14835608836993722, 0.14821589514387415, 0.14807634087334234, 0.1479374016157947, 0.1477990465012042, 0.1476612597689357, 0.14752405803304725, 0.1473874236338291, 0.14725137646384795, 0.14711592277270957, 0.14698104517472513, 0.14684676799931964, 0.14671307518376248, 0.1465799549636722, 0.14644741710453227, 0.1463154721426896, 0.14618412222201704, 0.14605335024232746, 0.14592315272961975, 0.14579355967079405, 0.14566452150416104, 0.14553601611701739, 0.14540805013230731, 0.1452806331079088, 0.14515378634125387, 0.14502751321372026, 0.14490179175480228, 0.14477661688628018, 0.14465200916543464, 0.14452795177842478, 0.14440444380135367, 0.144281499161386, 0.14415909611365826, 0.14403721195125685, 0.1439158383973672, 0.1437949656921687, 0.14367457652955595, 0.14355468643395436, 0.14343529770192215, 0.14331639521699985, 0.14319803973730175, 0.1430802152279187, 0.14296291377961348, 0.14284614484641647, 0.14272988185617533, 0.1426141366612217, 0.14249886810685422, 0.14238406627695993, 0.14226971251356677, 0.14215583972882573, 0.14204247688969257, 0.1419296326329168, 0.14181727939414496, 0.141705433582823, 0.14159406752220158, 0.1414831866377203, 0.14137279345457862, 0.1412628786386835, 0.14115347619545326, 0.1410445891990973, 0.140936168264026, 0.14082820669317062, 0.14072073967482654, 0.14061373685834827, 0.14050720027036412, 0.14040113745384483, 0.1402955155603392, 0.14019035530531224, 0.14008565524536026, 0.1399814035130792, 0.13987758379118131, 0.13977421312778102, 0.13967128773589985, 0.13956881175234065, 0.13946679103929585, 0.13936520827256782, 0.1392640356221377, 0.1391632835875175, 0.13906294754588766, 0.13896301607364714, 0.13886350600428882, 0.1387644007582739, 0.1386657090762514, 0.13856742654162285, 0.13846955416675594, 0.13837208194002537, 0.1382750215950878, 0.13817834629303433, 0.13808206747140025, 0.1379861933392786, 0.13789074158054807, 0.13779568598912842, 0.13770104042264691, 0.1376068229153485, 0.13751300716307216, 0.1374195673397304, 0.13732649376125325, 0.13723379702364402, 0.13714149099879253, 0.13704957351979735, 0.13695805091374685, 0.13686691978305757, 0.13677615312439698, 0.13668574272180076, 0.13659568547446135, 0.1365059796855256, 0.13641662519847983, 0.13632766210696495, 0.13623906133328065, 0.13615077323742314, 0.13606282541448275, 0.13597527068224227, 0.13588807663011127, 0.13580120886882902, 0.13571471892950446, 0.13562856256148054, 0.1355427214334218, 0.13545722274083213, 0.13537206143159147, 0.13528721270096555, 0.1352026867749582, 0.13511849619138544, 0.1350346330461891, 0.13495109218194956, 0.13486787928485502, 0.1347849920020474, 0.13470240745163228, 0.13462011631213544, 0.13453811577628197, 0.13445641157925625, 0.13437502038363994, 0.13429393919342747, 0.13421316958960597, 0.13413270215870288, 0.13405251978118835, 0.13397262608095611, 0.13389300514275398, 0.13381364670160462, 0.13373454652346997, 0.13365572997555072, 0.1335772026274212, 0.13349894023648803, 0.1334209456655831, 0.1333432179924131, 0.13326576544144483, 0.13318860676268168, 0.13311174389621167, 0.1330351699296956])\n"
     ]
    }
   ],
   "source": [
    "# functions = ['sigmoid', 'tanh', 'relu']\n",
    "\n",
    "neurons = [100]\n",
    "layers = len(neurons)\n",
    "batch_size = 500\n",
    "epochs = 500\n",
    "# lr_dic = {'sigmoid':0.001,\"tanh\":0.00001,\"relu\":0.000001}\n",
    "features = 784\n",
    "best_weights = 0\n",
    "best_acc = 0\n",
    "cost_dic = {}\n",
    "best_fun = 0\n",
    "\n",
    "# running for sigmoid\n",
    "model = NeuralNetwork(layers, neurons, unique_labels, features, batch_size, epochs, \"sigmoid\", 0, 0.001)\n",
    "cost = model.train(X, Y)\n",
    "\n",
    "accuracy = model_acc(model)\n",
    "if accuracy > best_acc:\n",
    "    best_acc = accuracy\n",
    "    best_fun = 'sigmoid'\n",
    "    save_weights(model.weights)\n",
    "\n",
    "print(\"Sigmoid acccuracy is\",accuracy, \"cost is\",cost)\n",
    "cost_dic['sigmoid'] = cost\n",
    "\n",
    "\n",
    "# running for tanh\n",
    "model = NeuralNetwork(layers, neurons, unique_labels, features, batch_size, epochs, \"tanh\", 0, 0.00001)\n",
    "cost = model.train(X, Y)\n",
    "\n",
    "accuracy = model_acc(model)\n",
    "if accuracy > best_acc:\n",
    "    best_acc = accuracy\n",
    "    best_fun = 'tanh'\n",
    "    save_weights(model.weights)\n",
    "    \n",
    "print(\"Tanh, acccuracy is\",accuracy, \"cost is\",cost)\n",
    "cost_dic['tanh'] = cost\n",
    "\n",
    "\n",
    "# running for relu\n",
    "model = NeuralNetwork(layers, neurons, unique_labels, features, batch_size, epochs, \"relu\", 0, 0.000001)\n",
    "cost = model.train(X, Y)\n",
    "\n",
    "accuracy = model_acc(model)\n",
    "if accuracy > best_acc:\n",
    "    best_acc = accuracy\n",
    "    best_fun = 'relu'\n",
    "    save_weights(model.weights)\n",
    "\n",
    "print(\"Relu, acccuracy is\",accuracy, \"cost is\",cost)\n",
    "cost_dic['relu'] = cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJHPsFxkjIiK"
   },
   "source": [
    "#### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "g7FZ-ckR2zjY",
    "outputId": "db4a37c4-81b3-467d-ab7d-2b4df28af265"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8k2W+NvArS5O2NIG0TcrSlVJk\nFawr4qBzBI+OjueMGzAusxy3wQUcNwSHRWV1g0FH0UFcB6tQPYz60RnnvM7McVjEehCLIJRuYJe0\nTZuuSZrk/aMmpGnSLE+SJ3lyff/RJG1y+7Pl4t5lTqfTCSIiIoo5udgNICIiSlYMYSIiIpEwhImI\niETCECYiIhIJQ5iIiEgkDGEiIiKRKGP9gUZjZ1TeV6dLh8nUE5X3ThasoTCsn3CsoXCsoXDRqKFe\nr/H5vGR6wkqlQuwmJDzWUBjWTzjWUDjWULhY1lAyIUxERJRoGMJEREQiYQgTERGJhCFMREQkEoYw\nERGRSBjCREREImEIExERiYQhTEREkrB377/w3ns7I/6+K1c+Aoulb9Bzn3/+T6xZs0rwe8f8xCwi\nIqJouOCCC6PyvqtXr4vK+wIMYSIiSlCNjY14/PHfQS6Xw26345xzzkNPTw/uvnsJNm16EocOfY2i\novGoq6vF6tVr8corL0Gn0+Ho0SNobzfhxht/gQ8//DM6Otrx3HMvITU1FRs3roHR2Iju7l7ceuud\nOO+8C3DddT/F66+XoaHhezzxxApotSMxdmxuRP4bOBxNREQxYbHacbTOBIvVHpH3++yzT3Huuedj\ny5atWLz4AaSkqAAAVVXH8fXX/4eXX34NCxfejKNHv3V/j0KhxObNL2D8+Ak4dOhrbN78BxQXF6Oi\n4gD++tePoVKp8Oabb2Lt2ifxzDMbB33eq6/+Eb/+9e3YvPkFKBSRiU9JhLDDYkHHN5VwWCxiN4WI\niHywWO3YuKMCG/70FTbuqIhIEJ933gX4+OMPsWXLs7DZrMjKygIA1NRUY8qU6ZDL5SgunoDRo8e4\nv2fy5KkAgKysbEyceAYAQKfLQnd3F44e/RZnnXU2ACA7Ww+VKgVmc4f7e2tqTmDatBkA4P46oRI+\nhB0WC+qf3IBvlq9A/ZMbGMRERHGoptGM6oaBW/SqGzpR22QW/J7jx0/Aq6/uwIwZZ+HFF59DU1Pj\nD684IZfL3F8nk53+d4VC4fPfnU4nANkP/xxgs9kgk8k9vgbu93U4HILbD0gghPtqamCpOQEAsNSc\nQM+x70RuEREReSscrUXRmIHr/IrGaFCQoxX8np9++glOnDiOOXMuwW23LcKOHW8CAMaNy8XRo0fg\ndDpRU1ONxsaGoN5v8uQpqKg4AABoamqEXC6HRnP6CsL8/AIcOTIwtF1R8aXg9gMSWJiVWlgIVX4h\nrHU1AIDmHW8i9eHlUGqF/w8mIqLIUKsUeGhhKWqbzCjI0UKtEn5dYF5eAZ56ai3S0tIhl8vxm9/c\ng1OnTmLSpCnIy8vH7bf/AiUlZ6CwcDzk8sB9zksvvQxfffUlbr75ZvT29uHBB5cNev0Xv/gvrF27\nGu++uwNjx45Df79N8H+DzOnZ944Bo7Ez4u/Z/c0hnNr0tPtxyugxKPjdKsjV6oh/lpTp9Zqo/P9J\nFqyfcKyhcKwhYLVa8be//QVXXHEVent7ceON1+Gdd/4bSmVw/c5o1FCv1/h8PuF7wgCQVjIRqePG\noe/UKQCArbEBfbU1SP9h0p2IiJKHSqXCkSOHsXNnGeRyGW699c6gAzjW4rNVIZKr1Ziycjkq7loM\n2GyQqVRQeayGIyKi5HLffQ+J3YSgJPzCLBersQWwDYzPO61W9NXVitwiIiKi4UkmhDMmFEOVX+h+\n3LzjTfSbhS+BJyIiihbJhLAiNRX6a651P+5vakL9xnXcN0xERHFLMiEMDCzQUuacngu2NTZw3zAR\nEcUtSYWwXK1G/sOPQGnIcT/X+t4u9oaJiCTos8/+FtLXf/TRn/Hcc5ui1JrwSCqEAUCp1SLn5ze5\nH1tqa9gbJiKSmIaG7/Hpp5+I3QzBJLFFyVtayUSeokVEJGHPPLMB335bie3bX3YfNdnf349HH12N\nceNyMX/+f+JHP7oEhw4dREaGBk8+OdADbmkxYvnyB1FTU42FC2/GVVf9h5j/GdLrCQMDw9JcpEVE\nFF8sdiuOmU7AYrcKfq+FC2/GzJmluOCCC/GrX92GLVu24sorr0Z5+bsAgO+/P4XLL78SW7duR2en\nGVVVx9zPP/bYeqxb9xR27iwT3A6hJNkTBk4v0upvGji4m6doERGJx2K3YnPFVtR21qNAk4fFpXdA\nrVAJft/MzCxs2vQUtm3bis5OM844YzIAYMSIEZgwoQQAYDAY0NXVBQCYOnU6FAoFsrMN6O7uEvz5\nQkmiJ2yxW3G4+btBf7uSq9XIXfJbICUFAHiKFhGRiOrMJ1HbWQ8AqO2sR535ZETed9u2rTj//Avw\n/PMv41e/us39vOc1hQDcVxQOvb5QXAkfwq6/Xa36f89ic8XWQUHc39bGU7SIiOJAvjYXBZo8AECB\nJg/52lxB7yeXy2G329He3o5x43LhdDrxv//7d9hswm82iqWEH4729berEt14AEOvOWx9bxfSSyby\ndiUiohhTK1RYXHoH6swnka/NFTwUXVBQhKNHj2DkyJF49tknMXr0WFx33Xxs3LgG+/fvjVCroy/h\nrzIMNM/gfc3h2CX3I2Pa9Ii2QSp4BZowrJ9wrKFwrKFwvMowBK6/XXXK26BxZA752xW3KxERUbxK\n+DlhYCCIJxtKfA5vcLsSERHFK0mEcCA8U5qIiOJRUoQwz5QmIqJ4lBQhDPg+U7qvtka8BhERUdJL\nmhAGAHV+AWSqH+aNFQoodZniNoiIiJJaUoWwtaEBTusPh3nY7Ti1+RkOSRMRSdS2bVuxa5f450MP\nJ6lCOLWwkAu0iIgobgQVwmvXrsX8+fOxYMECfP311z6/5umnn8bNN98c0cZFGhdoERFJx0cf/Rkr\nVjyCRYtuxWuvbcNvfvNrLFp0K3bseHPQ11VUHMCjjz7kfnzllZfGuql+BQzh/fv3o7a2FmVlZViz\nZg3WrFkz5GuOHz+OL774IioNjDRfC7TYGyYiij6HxYKeo0cj2vFpamrEo4+uxoED+/GHP2zD88+/\njL///X/Q2NgYsc+IpoAhvGfPHsydOxcAUFxcjI6ODveVUC7r16/HfffdF50WRoHrFC0X9oaJiKLL\nYbGg/skNOPnkOtQ/uSFif+ZOnjwF335biZMn63HPPXfgnnvuQE9PNxobv4/I+0dbwBBuaWmBTqdz\nP87MzITRaHQ/Li8vx3nnnYdx48ZFp4VR4H2KFnvDRETR1VdTA0vNCQCApeZExLaIKpUpUCpTMGvW\nbDz33Et47rmX8PrrZZg5s9T9NTKZbND39Pf3R+SzIyHks6M973tob29HeXk5tm/fjqampqC+X6dL\nh1KpCPyFYfB3QLYvmbNK0f7n8eiuGvihaN+9C/mzSqFITY1K2xJFKDWkoVg/4VhD4eKxhnbNNLSX\nTEDXsePIKJmA3LOnCf7zVqNJRXq6ChdeeA5efvl5ZGQokZqaijVr1uCBBx7AiBFqZGSkIjfXgI4O\nE/R6DY4cOYKenp6ANYpVDQOGsMFgQEtLi/txc3Mz9Ho9AGDv3r1oa2vDjTfeCKvVirq6OqxduxbL\nli3z+34mU08Emj1UOLdeaC+/Ct3P/x4A0HOiBnV7KpL6hiXeviIM6yccayhcPNdw9JIH0Vdbg9SC\nQrR12oBOYXf/dnb2oafHipQUDa65Zj7mz18IuVyOOXMuQWenDd3dFqSk9CEraxyUShWuvfZ6TJ8+\nA6NHjx22RrG8RSngVYYVFRXYsmULtm/fjsrKSjzxxBPYsWPHkK87efIkHnnkEbzxxhvDNiRaPxzh\nFM37msMxd90LzVmlw3yHtMXzL28iYP2EYw2FYw2Fi6urDEtLSzF16lQsWLAAMpkMK1euRHl5OTQa\nDebNmxfRRsZaWslEqPLyYa2vAwC0fbAbI6ZMhVytFrllRESUDAL2hCMtnnrCwNDe8Ngl9yftkDT/\nBi0M6yccaygcayhcLHvCSXVili/crkRERGJJ+hDmdiUiIhJL0ocwMLQ33LzjTfSbzeI1iIiIkgJD\nGEN7w/1NTajfuI7D0kREFFUM4R+klUwccsNSpE50ISIi8oUh/AO5Wo3cJb8FUlIAADKVCqrRYwJ8\nFxERUfgYwh7629oA28AJLk6rFX11tSK3iIiIpIwh7CG1sJDblYiIKGYYwh64XYmIiGKJIeyF25WI\niChWJBPCff0WHDOdgMVuFfQ+3K5ERESxIokQttiteOz/bcKmr17E5oqtgoPY13YlDksTEVGkSSKE\n68wncbytBgBQ21mPOvNJQe8nV6uR//AjUBpy3M9xkRYREUWaJEI4X5uLCZmFAIACTR7ytbmC31Op\n1SLn5ze5H1tqa3h4BxERRVTA+4QTgVqhwoofL0HFiSPI1+ZCrVBF5n3zCyBTqeC0Wnl4BxERRZwk\nesIAkKpUo0Q3PmIBDADWhgY4rQPzyzy8g4iIIk0yIRwN3od3cLsSERFFEkN4GNyuRERE0cQQDoDb\nlYiIKFoYwgFwuxIREUULQzgIvrYrsTdMRERCMYSDxDOliYgo0hjCQeIiLSIiijSGcAh8LdLiKVpE\nRBQuhnAI5Go1cpf8FkhJAQCeokVERIIwhEPU39YG2GwAeIoWEREJwxAOkfcpWtyuRERE4WIIh8h7\ngRa3KxERUbgYwmHgdiUiIooEhnAYuF2JiIgigSEcJp4pTUREQjGEw+TrTOmWXe+yN0xEREFjCAug\n1Gqhv36++7G1vo69YSIiChpDWCD5Dwd3uDh/2ENMREQUCENYoLSSiVDl5bsft32wm0PSREQUFIaw\nQHK1Gvprr3c/5r5hIiIKlqRC2GK34pjpBCx2a0w/l/uGiYgoHJIJ4b5+CzZXbMWmr17E5oqtMQ1i\n7hsmIqJwSCaET7TVorazHgBQ21mPOvPJmH4+9w0TEVGoJBPC4zMLUKDJAwAUaPKQr82N6edz3zAR\nEYVKKXYDIiVVqcbi0jtQZz6JfG0u1ApVzNvg2jfc8PzvAZzeN5wxbXrM20JERPFPMiEMAGqFCiW6\n8aK2gfuGiYgoWJIZjo4X3vuGjTvLuFKaiIh8YghHmPe+Ya6UJiIifxjCUcCV0kREFAyGcBT4WinN\nAzyIiMgbQzhKlFotcn5+k/sxh6WJiMgbQziKfA1L99XWiNcgIiKKKwzhKJKr1chd8lvAtW1JoYBS\nlyluo4iIKG4whKOsv60NcO0VtttRv3Ed54aJiAgAQzjqUgsLBw1J201tnBsmIiIADOGoc62UVngM\nQ3PLEhERAQzhmFBqtSj43SpuWSIiokEYwjHia8tS3fo1HJYmIkpiDOEYSiuZCIVHb7i/uQldhytF\nbBEREYmJIRxDcrUahuvnD3qudec77A0TESWpoEJ47dq1mD9/PhYsWICvv/560GvvvPMObrjhBixY\nsACrVq2C0+mMSkODYbFbccx0Aha7VbQ2BDJiylQoc073hm1NjVykRUSUpAKG8P79+1FbW4uysjKs\nWbMGa9ascb/W29uLDz/8EG+99RbefvttnDhxAl999VVUG+xPX78Fmyu2YtNXL2Jzxda4DeKB1dLL\nuUiLiIgCh/CePXswd+5cAEBxcTE6OjrQ1dUFAEhLS8Nrr72GlJQU9Pb2oqurC3q9Prot9uNEWy1q\nO+sBALWd9agznxSlHcHwtUir9vFVDGIioiQTMIRbWlqg0+ncjzMzM2E0Ggd9zUsvvYR58+bh8ssv\nR15eXuRbGYTxmQUo0Ax8doEmD/naXFHaESzvc6XtpjauliYiSjLKUL/B15zv7bffjltuuQW33XYb\nzj77bJx99tl+v1+nS4dSqQj1Y4Py+GX3o7qtDkWZ+UhVqqPyGZGjgW7jE/jqtw+iv7UNwMBqaZXx\nJHRnzRStVXq9RrTPlgLWTzjWUDjWULhY1TBgCBsMBrS0tLgfNzc3u4ec29vbcezYMZx77rlITU3F\nnDlzUFFRMWwIm0w9EWj2UHq9Bp0mK7Jlo9FpsqIT8TknPJgC+gU3oeH537ufMRk70G/sFKU1er0G\nRpE+WwpYP+FYQ+FYQ+GiUUN/oR5wOHr27Nn45JNPAACVlZUwGAzIyMgAAPT392Pp0qXo7u4GABw6\ndAhFRUWRanNSGDFlKlR5+e7Hxp1lnBsmIkoSAXvCpaWlmDp1KhYsWACZTIaVK1eivLwcGo0G8+bN\nw1133YVbbrkFSqUSZ5xxBi699NJYtFsy5Go19Ndej1ObngZwepFWwe9WQanVitw6IiKKJpkzxht7\nozVMkshDMA6LBTWPrUJ/U4P7OYUuM+ZBnMg1jAesn3CsoXCsoXBxNRxN0efrpiW7qY3bloiIJI4h\nHCdcNy15BzG3LRERSRdDOI64glg+6vS+bF7yQEQkXQzhOKPUapFz482DnjO+9QaHpYmIJIghHIe8\nL3mwt5s4P0xEJEEM4TjkuuSBC7WIiKRNciGcCNcZBoMLtYiIpE8SIWyx2vFNVQvMvb0JcZ1hsLhQ\ni4hI2kK+wCHeWKx2bNxRgeqGTowt6IMpZ/B1hiW68SK3UBjXQi3P86WNb72B9OIJPFGLiCjBJXxP\nuKbRjOqGgZNNvq9XIkc9cD1gIlxnGCwu1CIikqaED+HC0VoUjRk4DqwoR4clpXdiyVl3YnHpHVAr\nVCK3LjK4UIuISJokcXa0xWpHh8WOkWoF1Kro3FUcD/rNZtQ+vgp2U5v7OaUhB4UrH4NcLfz+ZJ45\nKwzrJxxrKBxrKBzPjg6RWqXA1PFZkg5ggAu1iIikRhIhnEx4ohYRkXQwhBMQF2oREUkDQzgB+Vuo\nVb1iOaxGo4gtIyKiUDCEE5SvE7WcXZ2oeXQpg5iIKEEwhBOYK4hlGR6r7ux21K59nEPTREQJQJIh\nLJXzo4Oh1GpRsHwFoDi9MtzZaeYcMRFRApBcCFvsVkmdHx0MlV6PwifWQ6Y5fYwlD/MgIop/kgvh\nOvNJ1HYOPj86Gaj0ehStfoK3LhERJRDJhXC+NhcFmjwA0jo/Ohj+DvNo/esnDGIiojiU8LcoeVMr\nVFhcegfqzCeRr82VzPnRwfJ165Lp/XJ07vkc+Q8v581LRERxRHI9YWAgiEt045MugF28D/MAgP6m\nJs4RExHFGUmGcLJzHeahNAwOYh7oQUQUXxjCEqXUalG48jGMvuteKDzmiHmgBxFR/GAIS5hcrYb2\nrFIUrFjNAz2IiOIQQzgJ+DvQo+axlej8qoIrp4mIRMIQThK+DvRwtJvQ8PzvuZeYiEgkkg3hZDq6\nMli+DvQAAGt9HboOV4rUKiKi5CXJEE7GoyuD5T7QY+SoQc83v/k6WvbuY4+YiCiGJBnCyXp0ZbBc\nK6c9V007OtpxdN1G1Dy2ggu2iIhiRJIhnMxHVwZLqdWiYMXqIUPT/U1NqFnNICYiigVJhrDr6Mol\nZ92JxaV3JO3JWYG4hqa9D/VwdLSj9rGVDGIioiiTZAgDPLoyWK6had1/XjPoeXu7iVuYiIiiTLIh\nTMGTq9XImvfvSB9fOOh5bmEiIoouhjABGAjiM9etGXLMJTCwhYnXIRIRRZ6kQ5h7hUOjSE11H3Pp\nvYXJ9H45qlf/jsPTREQRJNkQ5l7h8PnawgQA9uZmDk8TEUWQZEOYe4WFcW1h8l45DXB4mogoUiQb\nwtwrLJzndYjykSMHvcbhaSIi4ZRiNyBaXHuF68wnka/N5ValMLmuQ0wvnoDax1bC3m5yv+Yanlbl\n5SN/6XLI1WoRW0pElHgk2xMGuFc4kjg8TUQUeZIOYYosDk8TEUWW5EOY25QiyzU8Xbjycb+rp08s\nfxhWo1GkFhIRJQ5JhzC3KUXPcMPTjvZ21Cx/GB37eDUiEdFwJB3C3KYUXZ7D00qDYfCLDgeaXn6B\nQ9RERMOQdAhzm1L0eQ5PG27/DSBXDHrdNURdvep3vJWJiMiLZLcoAdymFEtytRqjzjsf6UXjUbdx\nHRymtkGv243NqFm9Ajk33YIRU6ZyOxMRESTeEwa4TSnWVHo9xj+xzucKakdHOxduERF5kHwIc3V0\n7HkOUQ+ZK8bphVvt//u/6P7mEOeLiShpSXo42rU6urazHgWaPCwuvYM94hgaWLj1OLoOV6Ll3bfR\n39x8+kWHA82v/hEAIB81CvkPL4dKrxeppURE4pB0T5iro8UXaOEWwC1NRJS8JB3CXB0dP1wLtwrX\nrIdclzn0C37Y0nRi1aNo+WA3V1ITUVKQOZ1OZyw/0GjsjMr76vUan+9tsVu5OjpI/moYaQ6LBT3H\nvkN/RweaX9sOOOxDv0guR85/3QHNzJkJs5I6VvWTMtZQONZQuGjUUK/X+Hxe0nPCwMDq6HxtLoM4\njsjVamRMmw4ASJ94hs8tTa6esVGvx6jZP8KoOZdAqdWK0FoiougJKoTXrl2LgwcPQiaTYdmyZTjz\nzDPdr+3duxfPPPMM5HI5ioqKsGbNGsjl8TPKzcVZ8c21panrcCWM7+yA3WvrksNoRNv75Wjb/T4M\nt/waKaNGIq1kYsL0jomIhhMwhPfv34/a2lqUlZWhqqoKy5YtQ1lZmfv1FStW4PXXX8fo0aNx7733\n4p///CcuvvjiqDY6FL4WZ5XoxovcKvLkWryVMWUqzAf/Dy3vvA2Hx73FAAavpmbvmIgkImCXdc+e\nPZg7dy4AoLi4GB0dHejq6nK/Xl5ejtGjRwMAMjMzYTKZfL6PWLg4K3G4Fm+NX7Meo++6Fwo/W5Zc\nveMTDyzhimoiSmgBe8ItLS2YOnWq+3FmZiaMRiMyMjIAwP3P5uZmfP7551i8ePGw76fTpUOpHLpN\nJRL8TXw/ftn9qG6rQ1FmPlKVHMYcjr8axpYGObkXo3DO+Wj74gCqt78OW2vr0C/7Yd64LccAwyUX\nI2N8EXQzZ0CRmhr7Jv8gPuqX2FhD4VhD4WJVw5AXZvlaTN3a2oo777wTK1euhE6n8/Fdp5lMPaF+\nZFACrWbTODJRceIIF2cNIy5XVU6agYLH1qLn2Hew9/Sg5b2dQ+aNbU3NOFX2LoCBoWr9z66DMj09\n5nPHcVm/BMMaCscaChdXq6MNBgNaWlrcj5ubm6H3GCbs6urCbbfdhiVLluCiiy6KQFMjj4uzEpvn\namrNjJn+540xMFTd9NILA9+XrUfO/IW8MIKI4lbAOeHZs2fjk08+AQBUVlbCYDC4h6ABYP369fjF\nL36BOXPmRK+VAvHkLOkIdt4YABwtxoELI3gACBHFqYA94dLSUkydOhULFiyATCbDypUrUV5eDo1G\ng4suugjvv/8+amtrsXPnTgDAVVddhfnz50e94aFwLc6q7axHTpoeOSOGXipAicVzRXXX4UpYa+tg\n3vcv9Bubh3yt9zYnxYh0yFNSuNWJiEQn+ROzXMzWLmyqeBFNPc0ckvYj0eeSHBbLwGUR77ztM4y9\nybP10F8TufnjRK9fPGANhWMNhYurOWGpaOpuRlPPwB/M3C8sTZ694+EWcrk4Wjzmj7n3mIhEkDQh\n7Dkkzf3C0hbKQi4XDlkTkRiSJoTVChUWl96BKlM1IBO7NRQrroVc2hkz3b3j1vd2+R+u9jiZC4j8\nkDURkaekCWGXD6r/wq1KSci7d9xz7Ds4bTY4bLagh6xlI0dC/7Pr2UsmoohJqhDmOdIEDA5kIPgh\na2dHx6BesiuUXZdKADyliIhCk1QhnK/NRV7GONR3nUJexjjOCxOAMIasf+AZynK9Hr3/dgn6R2Zz\n6JqIgpZUIQwAMtngfxK5+Buytvf0oPn1VwF7v9/vdRiN7qMzgYFQHnn+LKjGjmMoE5FfSRXCdeaT\nqOs8NfDvnadQZarGlOwzRG4VxSPvIeuM6WeiY8+/oMzMhNNqDSqUTR/sdj9WGAzIuvJq9JvaoB6X\ny6M0iQhAkoWw53A0APy5+mMU64q4OIsCUmq1yPr3y92PXaGs0GjQ+uf3/S7scrE3N6N5u8eqa70e\n2Vf9B0OZKMklVQirFSpcXXw5nj+4DcBAb5iLsygcnqGsPfscdB2uhKq9BX3qEUGFssNoZCgTUXKF\nMAAUjyriOdIUUa6TulxH3blC2XbqeygydWj74L/R3zz8Iq/hQjnFkMN5ZSKJSpqzoz3xHGnfeOas\nMP7q57BY3Kuubd83+L1oIhDPxV7ylBRJ7lXmz6BwrKFwPDs6yrzPkeYCLYom70VemVdcEVYoey/2\nApIjmImkLClDmAu0SEyRCmXAdzB7nuwFgMFMFMeSMoR9LdBib5jEMlwo9zcbocjUBbXYy8X7ZC/g\n9BnYAGBrbuLiL6I4kZQhDAws0GJvmOKRdygDGLTYS5ljAJzOYc+89uZ5Brb7c7wWf3E4myj2kjaE\nuV2JEolrBTbOKnU/p5kxc1AwB3OIiCfvFdku3sPZAIe0iaIlaUMYAHI146CSp8DqsEElT+F2JUoo\nvoLZ82QvOJ1BnYHtzddwNsAhbaJoSOoQbupuhtVhAwBYHTacNJ/ivDAlNO+TvTzPwAYAh80W9jap\nYIe0AfaciYKV1CHsvUr63WPv4z7tXdCqMkRuGVFk+JpfBoYu/gpnOBvwP6QNDO0589ARoqGS8rAO\nT4dbj7rnhQEgJ92Ah8+9NykXaHGTvzBSqF+/2ewezpYrlXDYbGENaQ/H8zIL795z3qxStHXaIvZZ\nyUgKP4di42EdMVQ8qgg5aXo09Q6sMm3qaeZ2JUpa3sPZQGSHtIGhl1l4Mu4wQPcf1wI43Xvmqm2S\nsqTvCQMDx1g+++ULaP4hiA1pWbjv7OQblubfoIVJtvp5HsfpGtIOdzFYMDxXbTtsNg5x+5FsP4fR\nEMuesGRCWKNNw4FvvkfhaC3UKkXI389haf7yCsX6DXCFs2fP2XXoSDCXWYTD+/hO1+cm4ypu/hwK\nx+HoEFmsdqx74XMcq29H0RgNHlpYGnIQ+xqW5r5hotD5WwwGDBw6Eo3es6/jOwe1yccq7mQNaYov\nkgjhmkYzjtW3AwCqGzpR22TGxDxdSO+hVqiwaOZ/4fG9T6Hf2Q8FFNCljopGc4mSlr+Ads07a9OV\n6Ojodfeew1217W24VdzA8CETv1pBAAAW/klEQVTNIW+KJkmEcOFoLUryRrl7wgU52rDex9TXjn7n\nwC+6HXY8W/ECHj53cdLNDRPFmiucs/QaOHwMA3oeQuJatR3Oudr+BAppYPghbwY1hUtSc8JfVn6P\ngpzw5oQBwGK3YsP+ze4haQAYpR6ZNEHMuSRhWD/hwqmhw2IZdHynXDnQtxC6ijsc3kHtGdKxWuXN\nn0PhuDArDJEqmtnahQ1fbEa7pcP9XLIEMX95hWH9hItGDX2t4nb1pmMd0oD/Vd6u3jUg7MQx/hwK\nxxAOQySL5iuIDWl6LD1vsaRXS/OXVxjWTzgxajhcSEdyyDtUvk4cC2aumj+HwjGEwxDpopmtXVi/\nfxM6rGb3c7dPuwUzDNMi9hnxhr+8wrB+wsVrDYcb8hYzqIGhQ+CaNAVajtdyFbgA3KIUB7SqDNxw\nxs/w8qHX3M+VHftvFI0qlPywNBEN5uvGKm/edz579qYjtcrbF+/tWQ3DfK1cr4f+Z8P3rnkJR2yx\nJzwMi92K9fufRXNvq/s5Kc8Px2svJFGwfsJJvYa+zub2HgKP1olj4QhmSDxSc9nxhMPRYYjWL28y\nLdSS+h+A0cb6Ccca+j9xLF7mqgMJNrgdNhv621ox8sKLoNSGt600WhjCYYjmL6+vIB6hHIGHzr0H\n2WmZUflMMfAPQGFYP+FYw9D4mqvWpCnQerxe9FXgQZPLYbjl15CpUgL2tmO1L5shHIZo//L6CmI5\n5Fg56yHJBDH/ABSG9ROONRTOXw09e9j+etfRvoQj0gLty/b3ONAiNYZwGGLxy2u2duGJvU+ju7/b\n/VyGcgSWX3C/JIam+QegMKyfcKyhcJGoYbBD4vE6lx0Mf4vUonWvNUM4Qlp627B6z0Y44HA/N1Kl\nxQ1n/AyTM0sSeh8x/wAUhvUTjjUUTqwahhrc9p4etLy3C452U8zbGsiICeMx5r6HIzrUzRCOoJbe\nNjz5xRZ0efSIASA7NRP3n3N3wvaK+QegMKyfcKyhcIlUw2CHyMXYl5370CNIn3hGxN4vKfYJW6x2\n1DSaw75TOFjZaZlYfsH9Q+aIW/rasG7fJsyflPi9YiKiaBvu2stAAu3L9vc4mEVqIyaMR2pBYZj/\nVaGRTE9Yo03DQ1v+geqGzrDvFA7VwKlam9Fh7Rjy2kiVFr89e1FCLdpKpL9BxyPWTzjWUDjWMLDh\neuDyFBXyZp0VszlhyfSEj59sR3XDwA9euHcKh0qrysDS8xbjmQPPw9jXOui1DqsZq/ZswC+nLMR0\n/RT2iomI4kSgHrgiNRWIcAj7bUtMPiUGJuSOQtGYgb9pCLlTOFRaVQYeOf8+3D7tFujTsga95oQT\n2w//Cev2PYP/M1bCYrfGpE1ERJQYJNMTTlUr8dDCUtQ2mQXdKRwOtUKFGYZpmJQ1EYeMlXjt8Ntw\n4PQov7GvDS8feg1Zah2umXg154uJiAiAhEIYANQqRdSHoIf9fIUK54w+C4UjC/Dsly+g3WuuuNVi\nwsuHXoM+NRP/WfJThjERUZKTVAjHi+y0TKyY9SCOtH6Hsu/eH3QdIsCeMRERDZBUCMdqi1IwXEPU\nRaMKfS7cAk73jLPVOlww9jzMHnd+wu4xJiKi0EkmhPss/di4oyKmW5SC4Vq4VWWqRq+9F7uOfTCk\nZ9xiMeGD6k/wUfVf8fNJ1yFdmYoURQqKRxWxh0xEJGGSCWExtigFS61QYUr2wMkrJboJfnvGDjjw\n5pF33I+1KRpcW/JTbnEiIpIoyYSwa4uSqyccqy1KofLuGe+u+hgtfW0+v9Zs68T2w39CljoTl4+f\ni25rF84fcw6HrImIJEIyJ2bp9RqcPNWOY6dMcDpkmJg3Ki6GowOx2K04ZKzEe8c/RLvXMLUvcsij\nNmTNk3aEYf2EYw2FYw2Fi+VVhpLpCbu894/quJsXHo5rW9N0/VRUmarR7+xHT38v/vTtTtg9bmpy\n8R6yzlLr8NMJV0AlU3IemYgowUgqhGsazXE7LxyI57wxAEzJmoTPT+7D3sYDaPExf+zSajHh1co/\nuR8zlImIEoekQrhwtDYh5oWDoVVl4Irxl+LfCn6EKlM1zLZO/Lnq44BD1sOFMgAGMxFRHJFUCKtV\nCjy0sNQ9LywFnj3kswxneizo+mTYHrKLdygDp4NZ5nTCZOngYi8iIpFIKoRdEm1eOFiegTwte4p7\nDtnmsAUdysDQYN5d9TF+Puk6ZPZocKKpHtnp2RihTGOPmYgoyoIK4bVr1+LgwYOQyWRYtmwZzjzz\nTPdrFosFK1aswLFjx1BeXh61hgbLe1742CkTphVli9yqyPOeQxYSyt6LvVyy1TqcM7oUozNyoJIp\nYXPY2HMmIoqggCG8f/9+1NbWoqysDFVVVVi2bBnKysrcr2/cuBGTJ0/GsWPHotrQYBWO1qIgJwO1\nTV0AgPK/V6NknE4yvWF/hgtlACEHMzBwktfHtX8b8ryr55wiV8DY24rs9GwuBCMiCkPAEN6zZw/m\nzp0LACguLkZHRwe6urqQkTHQE7rvvvvQ3t6O3bt3R7elQVKrFLhmTjGeffcgAKCmUbq94eF4hzIw\nNJh7+nuDWuzlzV/PGfDdezb2tmJMxhheVEFE5CVgCLe0tGDq1Knux5mZmTAaje4QzsjIQHt7e9Af\nqNOlQ6mMTq/UtRn6Qm0adv+rBlWnBq4S3P15LWbNyEOqWpJT4CHJHZ016PG8KRfiqLEKVocNVrsN\nTV1GZKaNws7Kj9Dc3RLy+/vrPQOAIT0b1029Am29HcjJyEaKQgWr3YbmLiNyMrIxQjUCk/TFSFWq\nw/pviwf+NuRT8FhD4VhD4WJVw5BTSegBWyZTj6Dv98f7hJOrLyx094aPn+zAnoP1SdcbDtZYZR6A\nwTWccM5EHGn9Dg09zchOy4JKrgy75+zS3NOCP3zxxrBf468n7RryBuJ3mxVPKhKONRSONRQurk7M\nMhgMaGk53SNqbm6GXq+PXMuiZGLeqKScG44U11WMM7yed22Tci0AM/a2ITstCzI4hz0HO1jD9aQ9\naVM0uLr4CqQrU4cENYfAiShRBAzh2bNnY8uWLViwYAEqKythMBjcQ9HxzNfccCKdoBWvfM01u0zL\nnjKk92xz2NDQ3YwvGr8KaVFYIGZbp995aU+uyy86+tqHhLRn75orv4lIDAFDuLS0FFOnTsWCBQsg\nk8mwcuVKlJeXQ6PRYN68ebj33nvR2NiI6upq3Hzzzbjhhhvw05/+NBZtD6hgtAaqFDmsNgcUCkCn\nSRW7SZLmr/cMAPMKLnEfNOLqPbtC2tjbhpHqkfi4+q+Ce9LeWi1teOvbwGHt4m/lt7/etueeaiKi\nUEnqFiXv9z5aZ8KGP33lfpypUWPFL8+FdgSHJ30Rey7JYrf67El7hvZwl1uIKVutwyXFs5AhGzVs\nb9s7yNn7Hkzsn0EpYA2Fi+WcsKRD2GK1Y/Wr+9HY1ut+jkHsX6L88pqtXdj3/ZfQpY3yGdTRGgKP\nFtf1lKH0vr2DXSrz34nyMxjPWEPhGMJh8Fc0c7cVj736Bdo6Le7nGMS+Se2X12K3DjsE7noMhL9n\nOp4EM/8dymMxji6V2s+gGFhD4RjCYRiuaL6CeFSGCqt+dR6D2EOy//K6Qtt75be/3nY057LjhT41\nE5cVRS7YXT14wPdWs2T/GYwE1lA4hnAYAhXN3G3F6u37Yeqyup/TaVRY+UsGsQt/ecPjmss2y9qR\n5tD47W37mt9O9N63UJ43ehl7W1Gck4verv6IBL3YvXqx8PdYOIZwGIIp2lffGbGl/NCg53QZKtx0\n2RmYUpiZ9HuI+csrTDj1C6f37R3siTT/LaZAB8EIDfp4OVyGv8fCMYTDEEzRLFY71r35Jeqau4a8\nZhiZimW3nJPUvWL+8gojZv2Cnf8OZZj9k5pPYexlsEeCd49fSLAHepyakeK+ktTX6/F64lw8YQiH\nIdiiWax2HK5txZt/OQaTxxwxAIzKSMGCf5uINLUSE/NGJV3PmCEsjNTqF+lg93wc6o1eFFlijAoE\n+zgeVvozhMMQatHM3Vas2r4f7R5zxJ6SsWcstRCJNdYveJ7D8MDp+fLxOePQ1xX60Pxwc/BSXzwn\nRb5W+gORC/rh3jNFkYLzJ0xHp8l3NoSLIeyDuduKtW8eQLOpz+frydYzZogIw/oJF60aBnMQjJCg\n9/U1A+eps8efiMbr8nH3mbdHtDfOEPbDNTxd9j9VaDb1+v06vVaNay+ZIOlAZogIw/oJJ7Ua+uvx\nhxvswTxOzVDiRNOpYf5iIPyilWSw5Kw7UaIbH7H3C/sWJalTqxQ4q8SAKQVZOFzbirf/dhzG9qE9\nY6PZghd3VwIA9CPVmDVtNApytFxVTUR+DXfhSbTo9RpMTPP/mf4uWonmqECwj+Nlpf94XT7ytbkx\n+ayk7wl7C7Zn7P5crRpXXzQe5h4rZk8fk9BzyFLrhcQa6yccayhcotfQ34JAIDJBH+g9UxQpOK94\nGueEQxXpHzxXGPvrGfsilwO/vHwSUhRytHVaEi6UE/2XV2ysn3CsoXCsoXCxXB2d9MPR/ngOUx87\nZYLN5oSt34Fd/6jyG8oOB/DKR0fcj3f9o8odys3tvcjVZ3D4moiI3BjCAahVCkwrynY/njEhG4dr\nW1Hb0IU9hxuH7SV7hzJwevi6rbMPObp0SS/0IiKi4TGEQ+TqIZ9VYsAVFxTg2CkTOjptKP9H1aBz\nqf0xmi3Y9tG3g55zLfQam5UBpUIGAEhRKhjOREQSxxAWwLOXfM4kg3vYuqevP+hQBgBjhwW7P68d\n8vzIESm49uJipKuVsPU7OKRNRCQxDOEI8R629gxlW78D37d0Bxy+9tbRbRsynA0MHdJWKmSw9TsS\ncjEYEVEyYwhHiXcoA3APX/f02tFs6oVOo8buf1WHFMyA7yFtF+/FYK6QduEwNxFR/GAIx5CvYD5n\nkgGHa1txqrkHBl0aUpRy9PT147WPv0W/I/TP8LUYzJvr9C+n0zkoqLWNnejttjKkiYhihCEsstML\nvQY/P704C3u++R46zUAwhzuk7Yvn6V+++AtpzksTEUUWQzhOaUeo8O/nFw553ntI27P3HMpisOEE\nCmnA97w0AHdQu57j8DcRkX8M4QTja0jbxXsxmGdIBzpoJFTDzUt787XK27t3zT3TRJSMGMISMlxA\nAwMHjbhCGsCgoAaA9z4/gabWwOdlh8rfKm9fvPdMe4e2u90MbiKSAIZwEgkU0pdeUIg9B+t9hnSk\n56X98bdnejiBgtvXY27nIqJ4wBAmt1S1ctiQdvE3Lw0MDm5bvyPsVd6hCCe4gdPbuQINk3PYnIii\nhSFMIQvUo/bka5W3d+9ayJ5pIYLZzuWPr953l+17aFQKDqMTUdAYwhRV/lZ5++Jrz7R3aAMQNbhd\nwu19ewpnGN072Ln6nCixMYQpbvjbMz2cYILb+3Ekt3MJEYkgB4Jffc5hdqL4wxCmhBZOcAODt3MB\nvhehxcuweSChrD4PxNeNXkKCnXvFiYbHEKakFMq8tjd/ve8uqx0ZKkVcD6MHEqneuTfP3jrgP9gn\n5OvQ22NlD56ShszpdDpj+YFGY2dU3lev10TtvZMFayhMKPWzWO0hD6P7GlaPxerzRBCNHnyibm3j\n77Fw0aihXq/x+TxDmNxYQ2HEqJ+52xrU6vNEHGaPV3I5wtraFuxiO6Hhz99j4RjCYeAPnnCsoTCJ\nXj9fvXMg+PlyX49jtVc8GbjC3/uaUu/QTk1XoarOFHLQc57/tFiGMOeEiQhA+IvcAvHeKw74D/YJ\n+aPQ22tjD94HIfvaoyHYef5ojxIk+loBhjARRVUoe8XD6YH4WigHCOvBx/PWtngRyVX50RLqWfSu\nXv6F2rSYtZHD0eTGGgrD+gkX7zW0WO1hbW0L9rGv92T4x96E3JG4/4aZEe1FcziaiEggIVvbhAh0\nTann49S0FFTVtYcU9JznH+z4yQ7UNpkxMU8X9c9iCBMRxblQwl+v12By3qiotieUef5ojhJEa63A\nhNyRKMjRRqxew2EIExFRSEKZ5xdLqGfRu55LUSowa+Y4dJojf7e6LwxhIiKSHCGr/VPVSsRqZYI8\nRp9DREREXhjCREREImEIExERiYQhTEREJBKGMBERkUgYwkRERCJhCBMREYmEIUxERCQShjAREZFI\nGMJEREQiYQgTERGJhCFMREQkEoYwERGRSGROp9MpdiOIiIiSEXvCREREImEIExERiYQhTEREJBKG\nMBERkUgYwkRERCJhCBMREYlEKXYDImHt2rU4ePAgZDIZli1bhjPPPFPsJsWt7777DosWLcIvf/lL\n3HTTTWhoaMBDDz0Eu90OvV6PJ598EiqVCrt378Zrr70GuVyOG264Addff73YTY8bGzduxJdffon+\n/n7ccccdmD59OmsYpN7eXixduhStra2wWCxYtGgRJk2axPqFoa+vD1dddRUWLVqEWbNmsYYh2Ldv\nHxYvXoySkhIAwMSJE3HrrbeKU0Nngtu3b5/z9ttvdzqdTufx48edN9xwg8gtil/d3d3Om266yfno\no48633jjDafT6XQuXbrU+dFHHzmdTqfz6aefdr711lvO7u5u52WXXeY0m83O3t5e55VXXuk0mUxi\nNj1u7Nmzx3nrrbc6nU6ns62tzXnxxRezhiH48MMPnS+99JLT6XQ6T5486bzssstYvzA988wzzmuu\nuca5a9cu1jBEe/fudd5zzz2DnhOrhgk/HL1nzx7MnTsXAFBcXIyOjg50dXWJ3Kr4pFKp8PLLL8Ng\nMLif27dvHy699FIAwI9//GPs2bMHBw8exPTp06HRaJCamorS0lJUVFSI1ey4cu6552Lz5s0AAK1W\ni97eXtYwBD/5yU9w2223AQAaGhqQk5PD+oWhqqoKx48fxyWXXAKAv8eRIFYNEz6EW1paoNPp3I8z\nMzNhNBpFbFH8UiqVSE1NHfRcb28vVCoVACArKwtGoxEtLS3IzMx0fw1reppCoUB6ejoAYOfOnZgz\nZw5rGIYFCxbggQcewLJly1i/MGzYsAFLly51P2YNQ3f8+HHceeedWLhwIT7//HPRaiiJOWFPTp7C\nGTZ/tWNNh/r000+xc+dOvPLKK7jsssvcz7OGwXn77bfx7bff4sEHHxxUG9YvsPfffx8zZ85EXl6e\nz9dZw8AKCwtx991344orrkB9fT1uueUW2O129+uxrGHCh7DBYEBLS4v7cXNzM/R6vYgtSizp6eno\n6+tDamoqmpqaYDAYfNZ05syZIrYyvvzzn//Eiy++iD/+8Y/QaDSsYQi++eYbZGVlYcyYMZg8eTLs\ndjtGjBjB+oXgs88+Q319PT777DM0NjZCpVLxZzBEOTk5+MlPfgIAyM/PR3Z2Ng4dOiRKDRN+OHr2\n7Nn45JNPAACVlZUwGAzIyMgQuVWJ48ILL3TX7y9/+Qt+9KMfYcaMGTh06BDMZjO6u7tRUVGBc845\nR+SWxofOzk5s3LgRW7duxahRowCwhqE4cOAAXnnlFQADU0k9PT2sX4g2bdqEXbt24Z133sH111+P\nRYsWsYYh2r17N7Zt2wYAMBqNaG1txTXXXCNKDSVxi9JTTz2FAwcOQCaTYeXKlZg0aZLYTYpL33zz\nDTZs2IBTp05BqVQiJycHTz31FJYuXQqLxYKxY8di3bp1SElJwccff4xt27ZBJpPhpptuwtVXXy12\n8+NCWVkZtmzZgqKiIvdz69evx6OPPsoaBqGvrw/Lly9HQ0MD+vr6cPfdd2PatGl4+OGHWb8wbNmy\nBePGjcNFF13EGoagq6sLDzzwAMxmM2w2G+6++25MnjxZlBpKIoSJiIgSUcIPRxMRESUqhjAREZFI\nGMJEREQiYQgTERGJhCFMREQkEoYwERGRSBjCREREImEIExERieT/A3vWLJmTWntwAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "activation_funs = ['sigmoid', 'tanh', 'relu']\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "x_axis = [i for i in range(epochs)]\n",
    "\n",
    "for f in activation_funs:\n",
    "    ax1.scatter(x_axis, cost_dic[f], s = 10, label=f)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z5450r4FjLNr"
   },
   "source": [
    "#### prediction of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5o9JZjSLrDYe"
   },
   "outputs": [],
   "source": [
    "best_fun = 'sigmoid'\n",
    "from numpy import savetxt\n",
    "def final_test():\n",
    "    test_filename = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/apparel-test.csv')\n",
    "    model = NeuralNetwork(layers, neurons, unique_labels, features, batch_size, epochs, best_fun, 1, 0.001)\n",
    "    pred = model.test(test_filename)\n",
    "    pred = np.argmax(pred, axis = 1)\n",
    "    savetxt('/content/gdrive/My Drive/Colab Notebooks/2018201103_prediction.csv', pred, fmt = \"%d\")\n",
    "    \n",
    "final_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZXechnNJ79iF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Q_1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
