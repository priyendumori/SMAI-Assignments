{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q-1-2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spliting features and class label and dropping numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = df.left\n",
    "X1 = df.drop(['left'],axis='columns')\n",
    "# axis = 0 means row and axis= 1 means columns. \n",
    "# default is 0. \n",
    "Z1 = pd.concat([X1,pd.get_dummies(X1['sales'], prefix='sales')],axis='columns')\n",
    "Z1 = pd.concat([Z1,pd.get_dummies(Z1['salary'], prefix='salary')],axis='columns')\n",
    "Z1 = Z1.drop(['sales','salary'],axis='columns')\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.2)\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(Z1, Y1,test_size=0.2)\n",
    "df11 = pd.concat([X_train1,Y_train1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy( df ):\n",
    "    Class = df.keys()[-1]\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = float(df[Class].value_counts()[value])/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction+eps)\n",
    "    return entropy\n",
    "\n",
    "#TESTING OF ENTROPY FUNC\n",
    "# c = pd.DataFrame({'rushit' : [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,11,1,1,1,1,1,1,1,1,1,1]})\n",
    "# x_ent = get_entropy(c.rushit)\n",
    "# x_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_entropy_attr( df,  attribute ):\n",
    "    Class = df.keys()[-1]\n",
    "    target_variables = df[Class].unique()  \n",
    "    variables = df[attribute].unique()\n",
    "    entropy2 = 0\n",
    "    for variable in variables:\n",
    "        entropy = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]==variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*np.log2(fraction+eps)\n",
    "        fraction2 = float(den)/len(df)\n",
    "        entropy2 += -fraction2*entropy\n",
    "    return abs(entropy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_to_select(df):\n",
    "    Entropy_att = []\n",
    "    IG = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        IG.append(get_entropy(df)-get_entropy_attr(df,key))\n",
    "    return df.keys()[:-1][np.argmax(IG)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtable(df, node, value):\n",
    "    return df[df[node] == value].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ent = get_entropy(df)\n",
    "def find_IG( df, val, attr ):\n",
    "    left = df[df[attr] < val ].reset_index(drop=True)\n",
    "    right = df[df[attr] >= val ].reset_index(drop=True)\n",
    "    left_ent = get_entropy(left)\n",
    "    right_ent = get_entropy(right)\n",
    "    return class_ent - ((float(len(left))/(len(df)+eps) * left_ent)+( float(len(right))/(len(df)+eps) * right_ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_numerical( attr , Y , attr_name):\n",
    "    max_ig = 0\n",
    "    max_split = None\n",
    "    pair = pd.concat([attr, Y], axis='columns')\n",
    "    pair = pair.sort_values(by =attr_name).reset_index()\n",
    "    for i in xrange( len(attr)-1):\n",
    "#         print i, pair[attr_name][i] , pair[attr_name][i+1]\n",
    "        if pair['left'][i] != pair['left'][i+1]:\n",
    "            cur_ig = find_IG( pair, float(pair[attr_name][i] + pair[attr_name][i+1])/2 , attr_name )\n",
    "            if cur_ig > max_ig:\n",
    "                max_ig = cur_ig\n",
    "                max_split =  float(pair[attr_name][i] + pair[attr_name][i+1])/2\n",
    "    return max_split"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print split_numerical(df['last_evaluation'], df['left'], 'last_evaluation')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clValue0,counts0 = np.unique(df['number_project'],return_counts=True)\n",
    "print clValue0\n",
    "print counts0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_actual( df, val, attr ):\n",
    "    df.loc[df[attr] < val, attr ] = 0\n",
    "    df.loc[df[attr] >= val, attr ] = 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satisfaction_level': 0.46499999999999997, 'last_evaluation': 0.58, 'average_montly_hours': 287.5, 'time_spend_company': 3.0, 'number_project': 2.5}\n"
     ]
    }
   ],
   "source": [
    "num_attr = [ 'number_project','last_evaluation', 'satisfaction_level','average_montly_hours','time_spend_company']\n",
    "split_dict = {}\n",
    "for attr in num_attr:\n",
    "    split_val = split_numerical(df[attr], df['left'],attr)\n",
    "    split_dict[attr] = split_val\n",
    "print split_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,split_dict):\n",
    "    for key,value in split_dict.iteritems():\n",
    "        change_actual(df, value, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(df,split_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.left\n",
    "X = df.drop(['left'],axis='columns')\n",
    "# axis = 0 means row and axis= 1 means columns. \n",
    "# default is 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doing One hot Encoding to convert multi-valued features to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.concat([X,pd.get_dummies(X['sales'], prefix='sales')],axis='columns')\n",
    "Z = pd.concat([Z,pd.get_dummies(Z['salary'], prefix='salary')],axis='columns')\n",
    "Z = Z.drop(['sales','salary'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.2)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Z, Y,test_size=0.2)\n",
    "df1 = pd.concat([X_train,Y_train],axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print attr_to_select(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        self.positive = 0\n",
    "        self.negative = 0\n",
    "        self.left = None\n",
    "        self.right = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Tree(df):\n",
    "    if len(df.columns) == 1:\n",
    "        return None\n",
    "    node_to_split = attr_to_select(df)\n",
    "    \n",
    "    root = Node(node_to_split)\n",
    "    root.positive = len( df[df['left']==1]['left'] )\n",
    "    root.negative = len( df[df['left']==0]['left'] )\n",
    "    \n",
    "    subtable0 = get_subtable(df,node_to_split,0)\n",
    "    subtable1 = get_subtable(df,node_to_split,1)\n",
    "    \n",
    "    subtable0 = subtable0.drop(node_to_split,axis=1)\n",
    "    subtable1 = subtable1.drop(node_to_split,axis=1)\n",
    "    \n",
    "#     print node_to_split\n",
    "#     print subtable0\n",
    "#     print subtable1\n",
    "#     print subtable0.shape\n",
    "#     print subtable1.shape\n",
    "    clValue0,counts0 = np.unique(subtable0['left'],return_counts=True)\n",
    "    clValue1,counts1 = np.unique(subtable1['left'],return_counts=True)\n",
    "    \n",
    "#     print clValue0, counts0\n",
    "#     print clValue1, counts1\n",
    "    \n",
    "    if len(counts0)<=1:\n",
    "#         print \"left\"\n",
    "        pass\n",
    "#         if len(counts0)==1:\n",
    "#             if clValue0[0]==0:\n",
    "#                 root.negative=counts0[0]\n",
    "#             else:\n",
    "#                 root.positive=counts0[0]\n",
    "    else:\n",
    "#         print \"else left\"\n",
    "        root.left = build_Tree(subtable0)\n",
    "        \n",
    "    if len(counts1)<=1:\n",
    "#         print \"right\"\n",
    "        pass\n",
    "#         if len(counts1)==1:\n",
    "#             if clValue1[0]==0:\n",
    "#                 root.negative=counts1[0]\n",
    "#             else:\n",
    "#                 root.positive=counts1[0]\n",
    "    else : \n",
    "#         print \"else right\"\n",
    "        root.right = build_Tree(subtable1)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print root.feature\n",
    "print root.left.feature\n",
    "print root.right.feature\n",
    "print root.left.left.feature\n",
    "print root.left.right.feature\n",
    "print root.right.left.feature\n",
    "print root.right.right.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_predict(df,root,Y1):\n",
    "#     print len(Y1)\n",
    "    if root == None:\n",
    "        return None\n",
    "    \n",
    "    if root.right==None and root.left==None:\n",
    "        Y1.append(1 if root.positive > root.negative else 0)\n",
    "        return\n",
    "    \n",
    "    if root.right==None and df[root.feature] == 1:\n",
    "        Y1.append(1 if root.positive > root.negative else 0)\n",
    "        return \n",
    "    if root.left == None and df[root.feature] == 0:\n",
    "        Y1.append(1 if root.positive > root.negative else 0)\n",
    "        return\n",
    "    \n",
    "    if df[root.feature]==0:\n",
    "        rec_predict(df,root.left,Y1)\n",
    "    else:\n",
    "        rec_predict(df,root.right,Y1)\n",
    "        \n",
    "def predict(df,root,Y1):\n",
    "    for col,row in df.iterrows():\n",
    "        rec_predict(row,root,Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = build_Tree(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1624   81]\n",
      " [ 270  273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      1705\n",
      "           1       0.77      0.50      0.61       543\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      2248\n",
      "   macro avg       0.81      0.73      0.76      2248\n",
      "weighted avg       0.84      0.84      0.83      2248\n",
      "\n",
      "0.8438612099644128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Yp1=[]\n",
    "# df2 = X_train.iloc[[0]]\n",
    "predict(X_test,root,Yp1)\n",
    "# Y1\n",
    "print confusion_matrix(Y_test,Yp1)\n",
    "print classification_report(Y_test,Yp1)\n",
    "print accuracy_score(Y_test, Yp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1657   41]\n",
      " [  25  525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1698\n",
      "           1       0.93      0.95      0.94       550\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2248\n",
      "   macro avg       0.96      0.97      0.96      2248\n",
      "weighted avg       0.97      0.97      0.97      2248\n",
      "\n",
      "0.9706405693950177\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(X_train1, Y_train1)\n",
    "Y_predict = model.predict(X_test1)\n",
    "print confusion_matrix(Y_test1,Y_predict)\n",
    "print classification_report(Y_test1,Y_predict)\n",
    "print accuracy_score(Y_test1, Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
