{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q-1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import log2 as log\n",
    "import pandas as pd\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get class label into Y and drop it from it from df and assign to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.left\n",
    "X = df.drop(['left'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.concat([X,pd.get_dummies(X['sales'],prefix='sales')],axis=1)\n",
    "Z = pd.concat([Z,pd.get_dummies(Z['salary'],prefix='salary')],axis=1)\n",
    "Z = Z.drop(['sales','salary'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split data into training(80%) and testing(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Z, Y,test_size=0.2)\n",
    "df1 = pd.concat([X_train, Y_train],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate entropy of class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_gini(df):\n",
    "    class_label = df.keys()[-1]\n",
    "    class_gini = 1\n",
    "    values = df[class_label].unique()\n",
    "    for val in values:\n",
    "        q = float(df[class_label].value_counts()[val])/len(df[class_label])\n",
    "        class_gini *= q\n",
    "    return class_gini*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate entropy of a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_gini(df, feature):\n",
    "    class_label = df.keys()[-1]\n",
    "    target_variables = df[class_label].unique()\n",
    "    variables = df[feature].unique()\n",
    "    gini = 0\n",
    "    for var in variables:\n",
    "        ent = 2\n",
    "        for t in target_variables:\n",
    "            n = len(df[feature][df[feature]==var][df[class_label]==t])\n",
    "            d = len(df[feature][df[feature]==var])\n",
    "            q = n/(d+eps)\n",
    "            ent *= q\n",
    "        q2 = float(d)/len(df)\n",
    "        gini += q2*ent\n",
    "    return abs(gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate IG of all features and select feature with maximum gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_to_select(df):\n",
    "    entropy_attr = []\n",
    "    gain = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        gain.append(class_gini(df)-feature_gini(df,key))\n",
    "    return df.keys()[:-1][np.argmax(gain)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtable(df,node,value):\n",
    "    return df[df[node]==value].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper function to calculate gain of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_gini = class_gini(df1)\n",
    "def compute_IG(df,val,feature):\n",
    "    l = df[df[feature]<val].reset_index(drop=True)\n",
    "    r = df[df[feature]>=val].reset_index(drop=True)\n",
    "    l_gini = class_gini(l)\n",
    "    r_gini = class_gini(r)\n",
    "    return cl_gini - ( (float(len(l))/(len(df)+eps)*l_gini) + (float(len(r))/(len(df)+eps)*r_gini) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the split point for numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_num_feature(data,cl_label,feature):\n",
    "    \n",
    "    max_ig = 0\n",
    "    max_split = None\n",
    "    pair = pd.concat([data,cl_label],axis=1)\n",
    "    pair = pair.sort_values(by=feature).reset_index()\n",
    "    for i in xrange(len(data)-1):\n",
    "        if pair['left'][i]!=pair['left'][i+1]:\n",
    "            ig = compute_IG(pair,float(pair[feature][i] + pair[feature][i+1])/2, feature)\n",
    "            if ig > max_ig:\n",
    "                max_ig = ig\n",
    "                max_split = float(pair[feature][i] + pair[feature][i+1])/2\n",
    "    return max_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change dataframe from numerical to 0 and 1 according to split point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_df(df,val,feature):\n",
    "    df.loc[df[feature]<val,feature]=0\n",
    "    df.loc[df[feature]>=val,feature]=1\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the split point for all numerical features and get split values for all in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satisfaction_level': 0.46499999999999997, 'last_evaluation': 0.575, 'average_montly_hours': 274.5, 'time_spend_company': 2.5, 'number_project': 2.5}\n"
     ]
    }
   ],
   "source": [
    "numerical_attributes=['number_project','last_evaluation', 'satisfaction_level','average_montly_hours','time_spend_company']\n",
    "split_values={}\n",
    "\n",
    "for at in numerical_attributes:\n",
    "    split = split_num_feature(df1[at],df1['left'],at)\n",
    "    split_values[at]=split\n",
    "print split_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocess data to perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,split_values):\n",
    "    for at,data in split_values.iteritems():\n",
    "        change_df(df,data,at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(df1,split_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### node of decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,feature,positive=0,negative=0):\n",
    "        self.feature=feature\n",
    "        self.positive=positive\n",
    "        self.negative=negative\n",
    "        self.left=None\n",
    "        self.right=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function that generates the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Tree(df):\n",
    "    if len(df.columns)==1:\n",
    "        return None\n",
    "    \n",
    "    split_node = feature_to_select(df)\n",
    "    root = Node(split_node)\n",
    "    root.positive=len(df[df['left']==1]['left'])\n",
    "    root.negative=len(df[df['left']==0]['left'])\n",
    "    \n",
    "    subtable_left = subtable(df,split_node,0)\n",
    "    subtable_right = subtable(df,split_node,1)\n",
    "    \n",
    "    subtable_left = subtable_left.drop(split_node,axis=1)\n",
    "    subtable_right = subtable_right.drop(split_node,axis=1)\n",
    "    \n",
    "    clValue_left,counts_left = np.unique(subtable_left['left'],return_counts=True)\n",
    "    clValue_right,counts_right = np.unique(subtable_right['left'],return_counts=True)\n",
    "    \n",
    "    if len(counts_left)>1:\n",
    "        root.left=build_Tree(subtable_left)\n",
    "    \n",
    "    if len(counts_right)>1:\n",
    "        root.right=build_Tree(subtable_right)\n",
    "        \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=build_Tree(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_predict(df,root,prediction):\n",
    "    if root==None:\n",
    "        return None\n",
    "    \n",
    "    if root.right==None and root.left==None:\n",
    "        prediction.append(1 if root.positive>root.negative else 0)\n",
    "        return\n",
    "    \n",
    "    if root.right==None and df[root.feature]==1:\n",
    "        prediction.append(1 if root.positive>root.negative else 0)\n",
    "        return\n",
    "    \n",
    "    if root.left==None and df[root.feature]==0:\n",
    "        prediction.append(1 if root.positive>root.negative else 0)\n",
    "        return\n",
    "    \n",
    "    if df[root.feature]==0:\n",
    "        rec_predict(df,root.left,prediction)\n",
    "    else:\n",
    "        rec_predict(df,root.right,prediction)\n",
    "        \n",
    "def predict(df,root,prediction):\n",
    "    for col,row in df.iterrows():\n",
    "        rec_predict(row,root,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform prediction with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1674   38]\n",
      " [ 218  318]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      1712\n",
      "           1       0.89      0.59      0.71       536\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2248\n",
      "   macro avg       0.89      0.79      0.82      2248\n",
      "weighted avg       0.89      0.89      0.88      2248\n",
      "\n",
      "0.8861209964412812\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "X1_test = X_test.copy(deep=True)\n",
    "\n",
    "prediction = []\n",
    "preprocess(X_test,split_values)\n",
    "predict(X_test,root,prediction)\n",
    "print confusion_matrix(Y_test,prediction)\n",
    "print classification_report(Y_test,prediction)\n",
    "print accuracy_score(Y_test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform prediciton with inbuilt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1667   45]\n",
      " [  27  509]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1712\n",
      "           1       0.92      0.95      0.93       536\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2248\n",
      "   macro avg       0.95      0.96      0.96      2248\n",
      "weighted avg       0.97      0.97      0.97      2248\n",
      "\n",
      "0.9679715302491103\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "Y_predict = model.predict(X1_test)\n",
    "print confusion_matrix(Y_test,Y_predict)\n",
    "print classification_report(Y_test,Y_predict)\n",
    "print accuracy_score(Y_test,Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['asffd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
