{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q-1-2 every node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import log2 as log\n",
    "import pandas as pd\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get class label into Y and drop it from it from df and assign to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.left\n",
    "X = df.drop(['left'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.concat([X,pd.get_dummies(X['sales'],prefix='sales')],axis=1)\n",
    "Z = pd.concat([Z,pd.get_dummies(Z['salary'],prefix='salary')],axis=1)\n",
    "Z = Z.drop(['sales','salary'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split data into training(80%) and testing(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Z, Y,test_size=0.2)\n",
    "df1 = pd.concat([X_train, Y_train],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate entropy of class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_entropy(df):\n",
    "    class_label = df.keys()[-1]\n",
    "    class_entropy = 0\n",
    "    values = df[class_label].unique()\n",
    "    for val in values:\n",
    "        q = float(df[class_label].value_counts()[val])/len(df[class_label])\n",
    "        class_entropy += -q*log(q)\n",
    "    return class_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate entropy of a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_entropy(df, feature):\n",
    "    class_label = df.keys()[-1]\n",
    "    target_variables = df[class_label].unique()\n",
    "    variables = df[feature].unique()\n",
    "    entropy = 0\n",
    "    for var in variables:\n",
    "        ent = 0\n",
    "        for t in target_variables:\n",
    "            n = len(df[feature][df[feature]==var][df[class_label]==t])\n",
    "            d = len(df[feature][df[feature]==var])\n",
    "            q = n/(d+eps)\n",
    "            ent += -q*log(q+eps)\n",
    "        q2 = float(d)/len(df)\n",
    "        entropy += -q2*ent\n",
    "    return abs(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the split point for numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_num_feature(data,cl_label,feature):\n",
    "    \n",
    "    max_ig = 0\n",
    "    max_split = None\n",
    "    pair = pd.concat([data,cl_label],axis=1)\n",
    "    pair = pair.sort_values(by=feature).reset_index()\n",
    "    found = set()\n",
    "    for i in xrange(len(data)-1):\n",
    "        if pair['left'][i]!=pair['left'][i+1] and (float(pair[feature][i] + pair[feature][i+1])/2) not in found:\n",
    "            found.add(float(pair[feature][i] + pair[feature][i+1])/2)\n",
    "            ig = compute_IG(pair,float(pair[feature][i] + pair[feature][i+1])/2, feature)\n",
    "            if ig > max_ig:\n",
    "                max_ig = ig\n",
    "                max_split = float(pair[feature][i] + pair[feature][i+1])/2\n",
    "    return max_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate IG of all features and select feature with maximum gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_attributes=['number_project','last_evaluation', 'satisfaction_level','average_montly_hours','time_spend_company']\n",
    "split_values={}\n",
    "\n",
    "def feature_to_select(df):\n",
    "    num_attr = [i for i in df.columns if i in numerical_attributes]\n",
    "    for at in num_attr:\n",
    "        split = split_num_feature(df[at],df['left'],at)\n",
    "        split_values[at]=split\n",
    "\n",
    "    gain = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        gain.append(class_entropy(df)-feature_entropy(df,key))\n",
    "    return df.keys()[:-1][np.argmax(gain)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtable(df,node,value):\n",
    "    return df[df[node]==value].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper function to calculate gain of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IG(df,val,feature):\n",
    "    cl_entropy = class_entropy(df)\n",
    "    l = df[df[feature]<val].reset_index(drop=True)\n",
    "    r = df[df[feature]>=val].reset_index(drop=True)\n",
    "    l_entropy = class_entropy(l)\n",
    "    r_entropy = class_entropy(r)\n",
    "    return cl_entropy - ( (float(len(l))/(len(df)+eps)*l_entropy) + (float(len(r))/(len(df)+eps)*r_entropy) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change dataframe from numerical to 0 and 1 according to split point"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def change_df(df,val,feature):\n",
    "    df.loc[df[feature]<val,feature]=0\n",
    "    df.loc[df[feature]>=val,feature]=1\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the split point for all numerical features and get split values for all in a dictionary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "numerical_attributes=['number_project','last_evaluation', 'satisfaction_level','average_montly_hours','time_spend_company']\n",
    "split_values={}\n",
    "\n",
    "for at in numerical_attributes:\n",
    "    split = split_num_feature(df1[at],df1['left'],at)\n",
    "    split_values[at]=split\n",
    "print split_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocess data to perform prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def preprocess(df,split_values):\n",
    "    for at,data in split_values.iteritems():\n",
    "        change_df(df,data,at)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preprocess(df1,split_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### node of decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,feature,positive=0,negative=0):\n",
    "        self.feature=feature\n",
    "        self.split_pos=0\n",
    "        self.positive=positive\n",
    "        self.negative=negative\n",
    "        self.left=None\n",
    "        self.right=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function that generates the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Tree(df):\n",
    "    if len(df.columns)==1:\n",
    "        return None\n",
    "    \n",
    "    split_node = feature_to_select(df)\n",
    "    root = Node(split_node)\n",
    "    if split_node in numerical_attributes:\n",
    "        split_point = split_values[root.feature]\n",
    "        root.split_pos = split_point\n",
    "        \n",
    "        root.positive=len(df[df['left']>=split_point]['left'])\n",
    "        root.negative=len(df[df['left']<split_point]['left'])\n",
    "        \n",
    "        subtable_left = df[df[split_node]<split_point].reset_index(drop=True)\n",
    "        subtable_right = df[df[split_node]>=split_point].reset_index(drop=True)\n",
    "    \n",
    "    else:\n",
    "        root.positive=len(df[df['left']==1]['left'])\n",
    "        root.negative=len(df[df['left']==0]['left'])\n",
    "        \n",
    "        subtable_left = subtable(df,split_node,0)\n",
    "        subtable_right = subtable(df,split_node,1)\n",
    "    \n",
    "    subtable_left = subtable_left.drop(split_node,axis=1)\n",
    "    subtable_right = subtable_right.drop(split_node,axis=1)\n",
    "    \n",
    "    clValue_left,counts_left = np.unique(subtable_left['left'],return_counts=True)\n",
    "    clValue_right,counts_right = np.unique(subtable_right['left'],return_counts=True)\n",
    "    \n",
    "    if len(counts_left)>1:\n",
    "        root.left=build_Tree(subtable_left)\n",
    "    \n",
    "    if len(counts_right)>1:\n",
    "        root.right=build_Tree(subtable_right)\n",
    "        \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=build_Tree(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_predict(df,root,prediction):\n",
    "    if root==None:\n",
    "        return None\n",
    "\n",
    "    if root.feature in numerical_attributes:\n",
    "        try:\n",
    "            if root.right==None and root.left==None:\n",
    "                prediction.append(1 if root.positive>root.negative else 0)\n",
    "                return\n",
    "\n",
    "            if root.right==None and df[root.feature]>=root.split_pos:\n",
    "                prediction.append(1 if root.positive>root.negative else 0)\n",
    "                return\n",
    "\n",
    "            if root.left==None and df[root.feature]<root.split_pos:\n",
    "                prediction.append(1 if root.positive>root.negative else 0)\n",
    "                return\n",
    "\n",
    "            if df[root.feature]<root.split_pos:\n",
    "                rec_predict(df,root.left,prediction)\n",
    "            else:\n",
    "                rec_predict(df,root.right,prediction)\n",
    "        except KeyError:\n",
    "            if root.left==None:\n",
    "                prediction.append(1 if root.positive>root.negative else 0)\n",
    "                return\n",
    "            rec_predict(df,root.left,prediction)\n",
    "    else:\n",
    "        try:\n",
    "            if root.right==None and root.left==None:\n",
    "                prediction.append(1 if root.positive>root.negative else 0)\n",
    "                return\n",
    "\n",
    "            if root.right==None and df[root.feature]==1:\n",
    "                prediction.append(1 if root.positive>root.negative else 0)\n",
    "                return\n",
    "\n",
    "            if root.left==None and df[root.feature]==0:\n",
    "                prediction.append(1 if root.positive>root.negative else 0)\n",
    "                return\n",
    "\n",
    "            if df[root.feature]==0:\n",
    "                rec_predict(df,root.left,prediction)\n",
    "            else:\n",
    "                rec_predict(df,root.right,prediction)\n",
    "        except KeyError:\n",
    "            if root.left==None:\n",
    "                prediction.append(1 if root.positive>root.negative else 0)\n",
    "                return\n",
    "            rec_predict(df,root.left,prediction)\n",
    "            \n",
    "def predict(df,root,prediction):\n",
    "    for col,row in df.iterrows():\n",
    "        rec_predict(row,root,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform prediction with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1649   62]\n",
      " [  51  486]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1711\n",
      "           1       0.89      0.91      0.90       537\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2248\n",
      "   macro avg       0.93      0.93      0.93      2248\n",
      "weighted avg       0.95      0.95      0.95      2248\n",
      "\n",
      "0.9497330960854092\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "X1_test = X_test.copy(deep=True)\n",
    "\n",
    "prediction = []\n",
    "# preprocess(X_test,split_values)\n",
    "predict(X_test,root,prediction)\n",
    "print confusion_matrix(Y_test,prediction)\n",
    "print classification_report(Y_test,prediction)\n",
    "print accuracy_score(Y_test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform prediciton with inbuilt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1660   51]\n",
      " [  23  514]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1711\n",
      "           1       0.91      0.96      0.93       537\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2248\n",
      "   macro avg       0.95      0.96      0.96      2248\n",
      "weighted avg       0.97      0.97      0.97      2248\n",
      "\n",
      "0.9670818505338078\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "Y_predict = model.predict(X1_test)\n",
    "print confusion_matrix(Y_test,Y_predict)\n",
    "print classification_report(Y_test,Y_predict)\n",
    "print accuracy_score(Y_test,Y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANS  2\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "ot = []\n",
    "test_rows=pd.read_csv('sample_test.csv')\n",
    "test_rows1 = pd.concat([test_rows,pd.get_dummies(test_rows['sales'],prefix='sales')],axis=1)\n",
    "test_rows1 = pd.concat([test_rows1,pd.get_dummies(test_rows1['salary'],prefix='salary')],axis=1)\n",
    "test_rows1 = test_rows1.drop(['sales','salary'],axis=1)\n",
    "# preprocess(test_rows1,split_values)\n",
    "predict(test_rows1,root,ot)\n",
    "print \"ANS \", len(ot)\n",
    "print ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
