{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q-1-3\n",
    "###### Contrast  the effectiveness of Misclassification  rate,  Gini,  Entropy as impurity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import log2 as log\n",
    "import pandas as pd\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input_data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get class label into Y and drop it from it from df and assign to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.left\n",
    "X = df.drop(['left'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.concat([X,pd.get_dummies(X['sales'],prefix='sales')],axis=1)\n",
    "Z = pd.concat([Z,pd.get_dummies(Z['salary'],prefix='salary')],axis=1)\n",
    "Z = Z.drop(['sales','salary'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split data into training(80%) and testing(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(Z, Y,test_size=0.2)\n",
    "df1 = pd.concat([X_train1, Y_train1],axis=1)\n",
    "df2 = pd.concat([X_train1, Y_train1],axis=1)\n",
    "df3 = pd.concat([X_train1, Y_train1],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function takes dataframe and flag as argument.\n",
    "```\n",
    "Flag: 1 - entropy\n",
    "      2 - gini\n",
    "      3 - misclassification rate\n",
    "Function takes argument and as per flag calculate measures for different type of impurities\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df1,flag):\n",
    "    \n",
    "    def class_imp(df):\n",
    "        if flag==1:\n",
    "            class_label = df.keys()[-1]\n",
    "            class_entropy = 0\n",
    "            values = df[class_label].unique()\n",
    "            for val in values:\n",
    "                q = float(df[class_label].value_counts()[val])/len(df[class_label])\n",
    "                class_entropy += -q*log(q)\n",
    "            return class_entropy  \n",
    "        elif flag==2:\n",
    "            class_label = df.keys()[-1]\n",
    "            class_gini = 1\n",
    "            values = df[class_label].unique()\n",
    "            for val in values:\n",
    "                q = float(df[class_label].value_counts()[val])/len(df[class_label])\n",
    "                class_gini *= q\n",
    "            return class_gini*2\n",
    "        elif flag==3:\n",
    "            class_label = df.keys()[-1]\n",
    "            class_mcr = 1\n",
    "            values = df[class_label].unique()\n",
    "            for val in values:\n",
    "                q = float(df[class_label].value_counts()[val])/len(df[class_label])\n",
    "                class_mcr = min(q,1-q)\n",
    "            return class_mcr\n",
    "    \n",
    "    def feature_imp(df, feature):\n",
    "        if flag==1:\n",
    "            class_label = df.keys()[-1]\n",
    "            target_variables = df[class_label].unique()\n",
    "            variables = df[feature].unique()\n",
    "            entropy = 0\n",
    "            for var in variables:\n",
    "                ent = 0\n",
    "                for t in target_variables:\n",
    "                    n = len(df[feature][df[feature]==var][df[class_label]==t])\n",
    "                    d = len(df[feature][df[feature]==var])\n",
    "                    q = n/(d+eps)\n",
    "                    ent += -q*log(q+eps)\n",
    "                q2 = float(d)/len(df)\n",
    "                entropy += -q2*ent\n",
    "            return abs(entropy)\n",
    "        elif flag==2:\n",
    "            class_label = df.keys()[-1]\n",
    "            target_variables = df[class_label].unique()\n",
    "            variables = df[feature].unique()\n",
    "            gini = 0\n",
    "            for var in variables:\n",
    "                ent = 2\n",
    "                for t in target_variables:\n",
    "                    n = len(df[feature][df[feature]==var][df[class_label]==t])\n",
    "                    d = len(df[feature][df[feature]==var])\n",
    "                    q = n/(d+eps)\n",
    "                    ent *= q\n",
    "                q2 = float(d)/len(df)\n",
    "                gini += q2*ent\n",
    "            return abs(gini)\n",
    "        elif flag==3:\n",
    "            class_label = df.keys()[-1]\n",
    "            target_variables = df[class_label].unique()\n",
    "            variables = df[feature].unique()\n",
    "            mcr = 0\n",
    "            for var in variables:\n",
    "                ent = 1\n",
    "                for t in target_variables:\n",
    "                    n = len(df[feature][df[feature]==var][df[class_label]==t])\n",
    "                    d = len(df[feature][df[feature]==var])\n",
    "                    q = n/(d+eps)\n",
    "                    ent = min(q,1-q)\n",
    "                q2 = float(d)/len(df)\n",
    "                mcr += q2*ent\n",
    "            return abs(mcr)\n",
    "\n",
    "    def split_num_feature(data,cl_label,feature):\n",
    "        max_ig = 0\n",
    "        max_split = None\n",
    "        pair = pd.concat([data,cl_label],axis=1)\n",
    "        pair = pair.sort_values(by=feature).reset_index()\n",
    "        found = set()\n",
    "        for i in xrange(len(data)-1):\n",
    "            if pair['left'][i]!=pair['left'][i+1] and (float(pair[feature][i] + pair[feature][i+1])/2) not in found:\n",
    "                found.add(float(pair[feature][i] + pair[feature][i+1])/2)\n",
    "                ig = compute_IG(pair,float(pair[feature][i] + pair[feature][i+1])/2, feature)\n",
    "                if ig > max_ig:\n",
    "                    max_ig = ig\n",
    "                    max_split = float(pair[feature][i] + pair[feature][i+1])/2\n",
    "        return max_split\n",
    "\n",
    "    numerical_attributes=['number_project','last_evaluation', 'satisfaction_level','average_montly_hours','time_spend_company']\n",
    "    split_values={}\n",
    "\n",
    "    def feature_to_select(df):\n",
    "        num_attr = [i for i in df.columns if i in numerical_attributes]\n",
    "        for at in num_attr:\n",
    "            split = split_num_feature(df[at],df['left'],at)\n",
    "            split_values[at]=split\n",
    "\n",
    "        entropy_attr = []\n",
    "        gain = []\n",
    "        for key in df.keys()[:-1]:\n",
    "            gain.append(class_imp(df)-feature_imp(df,key))\n",
    "        return df.keys()[:-1][np.argmax(gain)]\n",
    "\n",
    "    def subtable(df,node,value):\n",
    "        return df[df[node]==value].reset_index(drop=True)\n",
    "\n",
    "    def compute_IG(df,val,feature):\n",
    "        cl_imp = class_imp(df)\n",
    "        l = df[df[feature]<val].reset_index(drop=True)\n",
    "        r = df[df[feature]>=val].reset_index(drop=True)\n",
    "        l_imp = class_imp(l)\n",
    "        r_imp = class_imp(r)\n",
    "        return cl_imp - ( (float(len(l))/(len(df)+eps)*l_imp) + (float(len(r))/(len(df)+eps)*r_imp) )  \n",
    "\n",
    "    \n",
    "    class Node:\n",
    "        def __init__(self,feature,positive=0,negative=0):\n",
    "            self.feature=feature\n",
    "            self.split_pos=0\n",
    "            self.positive=positive\n",
    "            self.negative=negative\n",
    "            self.left=None\n",
    "            self.right=None\n",
    "\n",
    "    def build_Tree(df):\n",
    "        if len(df.columns)==1:\n",
    "            return None\n",
    "\n",
    "        split_node = feature_to_select(df)\n",
    "        root = Node(split_node)\n",
    "        if split_node in numerical_attributes:\n",
    "            split_point = split_values[root.feature]\n",
    "            root.split_pos = split_point\n",
    "\n",
    "            root.positive=len(df[df['left']>=split_point]['left'])\n",
    "            root.negative=len(df[df['left']<split_point]['left'])\n",
    "\n",
    "            subtable_left = df[df[split_node]<split_point].reset_index(drop=True)\n",
    "            subtable_right = df[df[split_node]>=split_point].reset_index(drop=True)\n",
    "\n",
    "        else:\n",
    "            root.positive=len(df[df['left']==1]['left'])\n",
    "            root.negative=len(df[df['left']==0]['left'])\n",
    "\n",
    "            subtable_left = subtable(df,split_node,0)\n",
    "            subtable_right = subtable(df,split_node,1)\n",
    "\n",
    "        subtable_left = subtable_left.drop(split_node,axis=1)\n",
    "        subtable_right = subtable_right.drop(split_node,axis=1)\n",
    "\n",
    "        clValue_left,counts_left = np.unique(subtable_left['left'],return_counts=True)\n",
    "        clValue_right,counts_right = np.unique(subtable_right['left'],return_counts=True)\n",
    "\n",
    "        if len(counts_left)>1:\n",
    "            root.left=build_Tree(subtable_left)\n",
    "\n",
    "        if len(counts_right)>1:\n",
    "            root.right=build_Tree(subtable_right)\n",
    "\n",
    "        return root\n",
    "\n",
    "    root=build_Tree(df1)\n",
    "\n",
    "    \n",
    "    def rec_predict(df,root,prediction):\n",
    "        if root==None:\n",
    "            return None\n",
    "\n",
    "        if root.feature in numerical_attributes:\n",
    "            try:\n",
    "                if root.right==None and root.left==None:\n",
    "                    prediction.append(1 if root.positive>root.negative else 0)\n",
    "                    return\n",
    "\n",
    "                if root.right==None and df[root.feature]>=root.split_pos:\n",
    "                    prediction.append(1 if root.positive>root.negative else 0)\n",
    "                    return\n",
    "\n",
    "                if root.left==None and df[root.feature]<root.split_pos:\n",
    "                    prediction.append(1 if root.positive>root.negative else 0)\n",
    "                    return\n",
    "\n",
    "                if df[root.feature]<root.split_pos:\n",
    "                    rec_predict(df,root.left,prediction)\n",
    "                else:\n",
    "                    rec_predict(df,root.right,prediction)\n",
    "            except KeyError:\n",
    "                if root.left==None:\n",
    "                    prediction.append(1 if root.positive>root.negative else 0)\n",
    "                    return\n",
    "                rec_predict(df,root.left,prediction)\n",
    "        else:\n",
    "            try:\n",
    "                if root.right==None and root.left==None:\n",
    "                    prediction.append(1 if root.positive>root.negative else 0)\n",
    "                    return\n",
    "\n",
    "                if root.right==None and df[root.feature]==1:\n",
    "                    prediction.append(1 if root.positive>root.negative else 0)\n",
    "                    return\n",
    "\n",
    "                if root.left==None and df[root.feature]==0:\n",
    "                    prediction.append(1 if root.positive>root.negative else 0)\n",
    "                    return\n",
    "\n",
    "                if df[root.feature]==0:\n",
    "                    rec_predict(df,root.left,prediction)\n",
    "                else:\n",
    "                    rec_predict(df,root.right,prediction)\n",
    "            except KeyError:\n",
    "                if root.left==None:\n",
    "                    prediction.append(1 if root.positive>root.negative else 0)\n",
    "                    return\n",
    "                rec_predict(df,root.left,prediction)\n",
    "\n",
    "    def predict(df,root,prediction):\n",
    "        for col,row in df.iterrows():\n",
    "            rec_predict(row,root,prediction)\n",
    "\n",
    "            \n",
    "    pd.options.mode.chained_assignment = None\n",
    "    X1_test = X_test1.copy(deep=True)\n",
    "\n",
    "    prediction = []\n",
    "    predict(X1_test,root,prediction)\n",
    "    print confusion_matrix(Y_test1,prediction)\n",
    "    print classification_report(Y_test1,prediction)\n",
    "    print accuracy_score(Y_test1,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function with entropy as impurity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1669   40]\n",
      " [  69  470]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1709\n",
      "           1       0.92      0.87      0.90       539\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2248\n",
      "   macro avg       0.94      0.92      0.93      2248\n",
      "weighted avg       0.95      0.95      0.95      2248\n",
      "\n",
      "0.9515124555160143\n"
     ]
    }
   ],
   "source": [
    "func(df1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function with gini as impurity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1669   40]\n",
      " [  66  473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1709\n",
      "           1       0.92      0.88      0.90       539\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2248\n",
      "   macro avg       0.94      0.93      0.93      2248\n",
      "weighted avg       0.95      0.95      0.95      2248\n",
      "\n",
      "0.952846975088968\n"
     ]
    }
   ],
   "source": [
    "func(df2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function with misclassification rate as impurity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1685   24]\n",
      " [ 312  227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      1709\n",
      "           1       0.90      0.42      0.57       539\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      2248\n",
      "   macro avg       0.87      0.70      0.74      2248\n",
      "weighted avg       0.86      0.85      0.83      2248\n",
      "\n",
      "0.8505338078291815\n"
     ]
    }
   ],
   "source": [
    "func(df3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "Impurity measures impacts the performance a lot\n",
    "\n",
    "Performance of gini and entropy is same for most cases. \n",
    "Gini is easier to compute compared to entropy.\n",
    "\n",
    "Misclassification rate is the worst performer among the three"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
