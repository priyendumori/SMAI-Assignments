{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q-1-1\n",
    "###### Decision tree with only categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### STEPS FOLLOWED:\n",
    "1. Read csv file to panda dataframe\n",
    "2. Apply one hot encoding to categorical features\n",
    "3. Split data to 80-20 for training and validation using train_test_split()\n",
    "4. Build Decision Tree using recursive function build_Tree()\n",
    "5. Apply predict method to predict class label and use inbuilt functions to calculate confusion matrix, classification report and accuracy score.\n",
    "6. Calculate the same measures using inbuilt scikitlearn decision tree to compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import log2 as log\n",
    "import pandas as pd\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input_data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get class label into Y and drop it from it from df and assign to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.left\n",
    "X = df.drop(['left','number_project','last_evaluation','satisfaction_level','average_montly_hours','time_spend_company'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.concat([X,pd.get_dummies(X['sales'],prefix='sales')],axis=1)\n",
    "Z = pd.concat([Z,pd.get_dummies(Z['salary'],prefix='salary')],axis=1)\n",
    "Z = Z.drop(['sales','salary'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split data into training(80%) and testing(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Z, Y,test_size=0.2)\n",
    "df1 = pd.concat([X_train, Y_train],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate entropy of class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_entropy(df):\n",
    "    class_label = df.keys()[-1]\n",
    "    class_entropy = 0\n",
    "    values = df[class_label].unique()\n",
    "    for val in values:\n",
    "        q = float(df[class_label].value_counts()[val])/len(df[class_label])\n",
    "        class_entropy += -q*log(q)\n",
    "    return class_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate entropy of a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_entropy(df, feature):\n",
    "    class_label = df.keys()[-1]\n",
    "    target_variables = df[class_label].unique()\n",
    "    variables = df[feature].unique()\n",
    "    entropy = 0\n",
    "    for var in variables:\n",
    "        ent = 0\n",
    "        for t in target_variables:\n",
    "            n = len(df[feature][df[feature]==var][df[class_label]==t])\n",
    "            d = len(df[feature][df[feature]==var])\n",
    "            q = n/(d+eps)\n",
    "            ent += -q*log(q+eps)\n",
    "        q2 = float(d)/len(df)\n",
    "        entropy += -q2*ent\n",
    "    return abs(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate IG of all features and select feature with maximum gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_to_select(df):\n",
    "    gain = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        gain.append(class_entropy(df)-feature_entropy(df,key))\n",
    "    return df.keys()[:-1][np.argmax(gain)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtable(df,node,value):\n",
    "    return df[df[node]==value].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### node of decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,feature,positive=0,negative=0):\n",
    "        self.feature=feature\n",
    "        self.positive=positive\n",
    "        self.negative=negative\n",
    "        self.left=None\n",
    "        self.right=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function that generates the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Tree(df):\n",
    "    if len(df.columns)==1:\n",
    "        return None\n",
    "    \n",
    "    split_node = feature_to_select(df)\n",
    "    root = Node(split_node)\n",
    "    root.positive=len(df[df['left']==1]['left'])\n",
    "    root.negative=len(df[df['left']==0]['left'])\n",
    "    \n",
    "    subtable_left = subtable(df,split_node,0)\n",
    "    subtable_right = subtable(df,split_node,1)\n",
    "    \n",
    "    subtable_left = subtable_left.drop(split_node,axis=1)\n",
    "    subtable_right = subtable_right.drop(split_node,axis=1)\n",
    "    \n",
    "    clValue_left,counts_left = np.unique(subtable_left['left'],return_counts=True)\n",
    "    clValue_right,counts_right = np.unique(subtable_right['left'],return_counts=True)\n",
    "    \n",
    "    if len(counts_left)>1:\n",
    "        root.left=build_Tree(subtable_left)\n",
    "    \n",
    "    if len(counts_right)>1:\n",
    "        root.right=build_Tree(subtable_right)\n",
    "        \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=build_Tree(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_predict(df,root,prediction):\n",
    "    if root==None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if root.right==None and root.left==None:\n",
    "            prediction.append(1 if root.positive>root.negative else 0)\n",
    "            return\n",
    "\n",
    "        if root.right==None and df[root.feature]==1:\n",
    "            prediction.append(1 if root.positive>root.negative else 0)\n",
    "            return\n",
    "\n",
    "        if root.left==None and df[root.feature]==0:\n",
    "            prediction.append(1 if root.positive>root.negative else 0)\n",
    "            return\n",
    "\n",
    "        if df[root.feature]==0:\n",
    "            rec_predict(df,root.left,prediction)\n",
    "        else:\n",
    "            rec_predict(df,root.right,prediction)\n",
    "    except KeyError:\n",
    "        if root.left!=Node:\n",
    "            prediction.append(1 if root.positive>root.negative else 0)\n",
    "            return\n",
    "        else:\n",
    "            rec_predict(df,root.left,prediction)\n",
    "            \n",
    "def predict(df,root,prediction):\n",
    "    for col,row in df.iterrows():\n",
    "        rec_predict(row,root,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform prediction with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1724    1]\n",
      " [ 523    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1725\n",
      "           1       0.00      0.00      0.00       523\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      2248\n",
      "   macro avg       0.38      0.50      0.43      2248\n",
      "weighted avg       0.59      0.77      0.67      2248\n",
      "\n",
      "0.7669039145907474\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "predict(X_test,root,prediction)\n",
    "\n",
    "print confusion_matrix(Y_test,prediction)\n",
    "print classification_report(Y_test,prediction)\n",
    "print accuracy_score(Y_test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform prediciton with inbuilt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1724    1]\n",
      " [ 522    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1725\n",
      "           1       0.50      0.00      0.00       523\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      2248\n",
      "   macro avg       0.63      0.50      0.44      2248\n",
      "weighted avg       0.71      0.77      0.67      2248\n",
      "\n",
      "0.7673487544483986\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "Y_predict = model.predict(X_test)\n",
    "print confusion_matrix(Y_test,Y_predict)\n",
    "print classification_report(Y_test,Y_predict)\n",
    "print accuracy_score(Y_test,Y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "ot = []\n",
    "test_rows=pd.read_csv('../input_data/sample_test.csv')\n",
    "test_rows1 = pd.concat([test_rows,pd.get_dummies(test_rows['sales'],prefix='sales')],axis=1)\n",
    "test_rows1 = pd.concat([test_rows1,pd.get_dummies(test_rows1['salary'],prefix='salary')],axis=1)\n",
    "test_rows1 = test_rows1.drop(['sales','salary'],axis=1)\n",
    "# preprocess(test_rows1,split_values)\n",
    "predict(test_rows1,root,ot)\n",
    "print ot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "To handle categorical features in a binary decision tree, they have to be encoded using one hot encoding or binary encoding or using other methods\n",
    "\n",
    "Using only some features of the data, the result is poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
